{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9efc991b",
   "metadata": {},
   "source": [
    "$\\newcommand{\\RE}{\\mathrm{Re}}$\n",
    "$\\newcommand{\\IM}{\\mathrm{Im}}$\n",
    "$\\newcommand{\\D}{\\mathcal{D}}$\n",
    "$\\newcommand{\\E}{\\mathcal{E}}$\n",
    "$\\newcommand{\\G}{\\Gamma}$\n",
    "$\\newcommand{\\OG}{\\Gamma^\\dagger}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d46d918e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10-element Vector{Float64}:\n",
       " 0.5\n",
       " 1.5\n",
       " 2.5\n",
       " 3.5\n",
       " 4.5\n",
       " 5.5\n",
       " 6.5\n",
       " 7.5\n",
       " 8.5\n",
       " 9.5"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "collect(0.5:1.0:(10-0.5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fa1d4f14",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.optimize import least_squares\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "51c066a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.718281828459045"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.exp(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bf6bf58b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1.00000000e+00, -7.18281828e-01, -3.38905610e+00, -1.40855369e+01,\n",
       "       -4.65981500e+01, -1.38413159e+02, -3.91428793e+02, -1.08263316e+03,\n",
       "       -2.96495799e+03, -8.08508393e+03, -2.20064658e+04])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "2*np.arange(11)-np.exp(np.arange(11)*1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a1768f7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def myfun(x):\n",
    "    k = np.arange(11)\n",
    "    return 2*k-np.exp(k*x[0]) - np.exp(k*x[1])       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b63f8253",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.24532273, 0.24531671])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res_1 = least_squares(myfun, np.array([0.3,0.4]))\n",
    "res_1.x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3b02a2bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "29.04688054837413"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res_1.cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0860bc56",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.004234346536918565"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res_1.optimality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "31a827ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res_1.status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c85ce3a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8.764461601900072"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.linalg.norm(myfun(np.array([0.2578,0.2578])), 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2ed21635",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m\u001b[1m    Updating\u001b[22m\u001b[39m registry at `C:\\Users\\Kamlesh\\.julia\\registries\\General`\n",
      "\u001b[32m\u001b[1m    Updating\u001b[22m\u001b[39m git-repo `https://github.com/JuliaRegistries/General.git`\n",
      "\u001b[32m\u001b[1m   Resolving\u001b[22m\u001b[39m package versions...\n",
      "\u001b[32m\u001b[1m   Installed\u001b[22m\u001b[39m OptimBase ─ v2.0.2\n",
      "\u001b[32m\u001b[1m   Installed\u001b[22m\u001b[39m LsqFit ──── v0.12.1\n",
      "\u001b[32m\u001b[1m    Updating\u001b[22m\u001b[39m `C:\\Users\\Kamlesh\\.julia\\environments\\v1.7\\Project.toml`\n",
      " \u001b[90m [2fda8390] \u001b[39m\u001b[92m+ LsqFit v0.12.1\u001b[39m\n",
      "\u001b[32m\u001b[1m    Updating\u001b[22m\u001b[39m `C:\\Users\\Kamlesh\\.julia\\environments\\v1.7\\Manifest.toml`\n",
      " \u001b[90m [2fda8390] \u001b[39m\u001b[92m+ LsqFit v0.12.1\u001b[39m\n",
      " \u001b[90m [87e2bd06] \u001b[39m\u001b[92m+ OptimBase v2.0.2\u001b[39m\n",
      "\u001b[32m\u001b[1mPrecompiling\u001b[22m\u001b[39m project...\n",
      "\u001b[32m  ✓ \u001b[39m\u001b[90mOptimBase\u001b[39m\n",
      "\u001b[32m  ✓ \u001b[39mLsqFit\n",
      "  2 dependencies successfully precompiled in 7 seconds (320 already precompiled)\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1a6c722b",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "using LsqFit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "644f1ae9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "g (generic function with 1 method)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g(κ, ζ) = κ[1] * exp.(κ[2] * ζ)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d98aa027",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2-element Vector{Float64}:\n",
       " 1.0\n",
       " 2.718281828459045"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g([1,1],[0,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6f4cac17",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2-element Vector{Array{Float64}}:\n",
       " [1.0, 1.0]\n",
       " [2.0, 2.0]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "κ0 = [0.5, 0.5]\n",
    "ydata = [0 , 0]\n",
    "ζdata = Array{Float64}[]\n",
    "for i=1:2\n",
    "    push!(ζdata,[i,i])\n",
    "end\n",
    "\n",
    "ζdata\n",
    "#fit = curve_fit(g, ζdata, ydata, κ0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "202a7b65",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "LoadError",
     "evalue": "MethodError: no method matching isinf(::Vector{Float64})\n\u001b[0mClosest candidates are:\n\u001b[0m  isinf(\u001b[91m::Complex\u001b[39m) at C:\\Users\\Kamlesh\\AppData\\Local\\Programs\\julia-1.7.2\\share\\julia\\base\\complex.jl:148\n\u001b[0m  isinf(\u001b[91m::DualNumbers.Dual\u001b[39m) at C:\\Users\\Kamlesh\\.julia\\packages\\DualNumbers\\ULBIj\\src\\dual.jl:53\n\u001b[0m  isinf(\u001b[91m::ForwardDiff.Dual\u001b[39m) at C:\\Users\\Kamlesh\\.julia\\packages\\ForwardDiff\\PBzup\\src\\dual.jl:336\n\u001b[0m  ...",
     "output_type": "error",
     "traceback": [
      "MethodError: no method matching isinf(::Vector{Float64})\n\u001b[0mClosest candidates are:\n\u001b[0m  isinf(\u001b[91m::Complex\u001b[39m) at C:\\Users\\Kamlesh\\AppData\\Local\\Programs\\julia-1.7.2\\share\\julia\\base\\complex.jl:148\n\u001b[0m  isinf(\u001b[91m::DualNumbers.Dual\u001b[39m) at C:\\Users\\Kamlesh\\.julia\\packages\\DualNumbers\\ULBIj\\src\\dual.jl:53\n\u001b[0m  isinf(\u001b[91m::ForwardDiff.Dual\u001b[39m) at C:\\Users\\Kamlesh\\.julia\\packages\\ForwardDiff\\PBzup\\src\\dual.jl:336\n\u001b[0m  ...",
      "",
      "Stacktrace:",
      " [1] _any",
      "   @ .\\reduce.jl:1110 [inlined]",
      " [2] #any#749",
      "   @ .\\reducedim.jl:899 [inlined]",
      " [3] any",
      "   @ .\\reducedim.jl:899 [inlined]",
      " [4] check_data_health(xdata::Vector{Array{Float64}}, ydata::Vector{Int64})",
      "   @ LsqFit C:\\Users\\Kamlesh\\.julia\\packages\\LsqFit\\hgZQe\\src\\curve_fit.jl:22",
      " [5] curve_fit(model::typeof(g), xdata::Vector{Array{Float64}}, ydata::Vector{Int64}, p0::Vector{Float64}; inplace::Bool, kwargs::Base.Pairs{Symbol, Union{}, Tuple{}, NamedTuple{(), Tuple{}}})",
      "   @ LsqFit C:\\Users\\Kamlesh\\.julia\\packages\\LsqFit\\hgZQe\\src\\curve_fit.jl:106",
      " [6] curve_fit(model::Function, xdata::Vector{Array{Float64}}, ydata::Vector{Int64}, p0::Vector{Float64})",
      "   @ LsqFit C:\\Users\\Kamlesh\\.julia\\packages\\LsqFit\\hgZQe\\src\\curve_fit.jl:106",
      " [7] top-level scope",
      "   @ In[17]:1",
      " [8] eval",
      "   @ .\\boot.jl:373 [inlined]",
      " [9] include_string(mapexpr::typeof(REPL.softscope), mod::Module, code::String, filename::String)",
      "   @ Base .\\loading.jl:1196"
     ]
    }
   ],
   "source": [
    "fit = curve_fit(g, ζdata, ydata, κ0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bb683ed",
   "metadata": {},
   "source": [
    "# ADNLP API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6fb5136a",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m\u001b[1m   Resolving\u001b[22m\u001b[39m package versions...\n",
      "\u001b[32m\u001b[1m   Installed\u001b[22m\u001b[39m NLPModels ─ v0.18.3\n",
      "\u001b[32m\u001b[1m    Updating\u001b[22m\u001b[39m `C:\\Users\\Kamlesh\\.julia\\environments\\v1.7\\Project.toml`\n",
      " \u001b[90m [a4795742] \u001b[39m\u001b[92m+ NLPModels v0.18.3\u001b[39m\n",
      "\u001b[32m\u001b[1m    Updating\u001b[22m\u001b[39m `C:\\Users\\Kamlesh\\.julia\\environments\\v1.7\\Manifest.toml`\n",
      " \u001b[90m [a4795742] \u001b[39m\u001b[92m+ NLPModels v0.18.3\u001b[39m\n",
      "\u001b[32m\u001b[1mPrecompiling\u001b[22m\u001b[39m project...\n",
      "\u001b[32m  ✓ \u001b[39mNLPModels\n",
      "  1 dependency successfully precompiled in 3 seconds (322 already precompiled)\n"
     ]
    }
   ],
   "source": [
    "import Pkg\n",
    "Pkg.add(\"NLPModels\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f488b283",
   "metadata": {},
   "outputs": [],
   "source": [
    "using NLPModels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "09bbd078",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "true"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "AbstractNLSModel <: AbstractNLPModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ddcd8ab3",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m\u001b[1m   Resolving\u001b[22m\u001b[39m package versions...\n",
      "\u001b[32m\u001b[1m   Installed\u001b[22m\u001b[39m ADNLPModels ─ v0.3.1\n",
      "\u001b[32m\u001b[1m    Updating\u001b[22m\u001b[39m `C:\\Users\\Kamlesh\\.julia\\environments\\v1.7\\Project.toml`\n",
      " \u001b[90m [54578032] \u001b[39m\u001b[92m+ ADNLPModels v0.3.1\u001b[39m\n",
      "\u001b[32m\u001b[1m    Updating\u001b[22m\u001b[39m `C:\\Users\\Kamlesh\\.julia\\environments\\v1.7\\Manifest.toml`\n",
      " \u001b[90m [54578032] \u001b[39m\u001b[92m+ ADNLPModels v0.3.1\u001b[39m\n",
      "\u001b[32m\u001b[1mPrecompiling\u001b[22m\u001b[39m project...\n",
      "\u001b[32m  ✓ \u001b[39mADNLPModels\n",
      "  1 dependency successfully precompiled in 8 seconds (323 already precompiled)\n"
     ]
    }
   ],
   "source": [
    "import Pkg\n",
    "Pkg.add(\"ADNLPModels\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0121ebc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "using ADNLPModels,  LsqFit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7133e624",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "LoadError",
     "evalue": "MethodError: no method matching ADNLSModel(::typeof(F), ::Vector{Float64})\n\u001b[0mClosest candidates are:\n\u001b[0m  ADNLSModel(::Any, ::S, \u001b[91m::Integer\u001b[39m; linequ, name, adbackend) where S at C:\\Users\\Kamlesh\\.julia\\packages\\ADNLPModels\\9yjtG\\src\\nls.jl:43\n\u001b[0m  ADNLSModel(::Any, ::S, \u001b[91m::Integer\u001b[39m, \u001b[91m::S\u001b[39m, \u001b[91m::S\u001b[39m; linequ, name, adbackend) where S at C:\\Users\\Kamlesh\\.julia\\packages\\ADNLPModels\\9yjtG\\src\\nls.jl:61\n\u001b[0m  ADNLSModel(::Any, ::S, \u001b[91m::Integer\u001b[39m, \u001b[91m::S\u001b[39m, \u001b[91m::S\u001b[39m, \u001b[91m::Any\u001b[39m, \u001b[91m::S\u001b[39m, \u001b[91m::S\u001b[39m; y0, lin, linequ, name, adbackend) where S at C:\\Users\\Kamlesh\\.julia\\packages\\ADNLPModels\\9yjtG\\src\\nls.jl:118\n\u001b[0m  ...",
     "output_type": "error",
     "traceback": [
      "MethodError: no method matching ADNLSModel(::typeof(F), ::Vector{Float64})\n\u001b[0mClosest candidates are:\n\u001b[0m  ADNLSModel(::Any, ::S, \u001b[91m::Integer\u001b[39m; linequ, name, adbackend) where S at C:\\Users\\Kamlesh\\.julia\\packages\\ADNLPModels\\9yjtG\\src\\nls.jl:43\n\u001b[0m  ADNLSModel(::Any, ::S, \u001b[91m::Integer\u001b[39m, \u001b[91m::S\u001b[39m, \u001b[91m::S\u001b[39m; linequ, name, adbackend) where S at C:\\Users\\Kamlesh\\.julia\\packages\\ADNLPModels\\9yjtG\\src\\nls.jl:61\n\u001b[0m  ADNLSModel(::Any, ::S, \u001b[91m::Integer\u001b[39m, \u001b[91m::S\u001b[39m, \u001b[91m::S\u001b[39m, \u001b[91m::Any\u001b[39m, \u001b[91m::S\u001b[39m, \u001b[91m::S\u001b[39m; y0, lin, linequ, name, adbackend) where S at C:\\Users\\Kamlesh\\.julia\\packages\\ADNLPModels\\9yjtG\\src\\nls.jl:118\n\u001b[0m  ...",
      "",
      "Stacktrace:",
      " [1] top-level scope",
      "   @ In[2]:5",
      " [2] eval",
      "   @ .\\boot.jl:373 [inlined]",
      " [3] include_string(mapexpr::typeof(REPL.softscope), mod::Module, code::String, filename::String)",
      "   @ Base .\\loading.jl:1196"
     ]
    }
   ],
   "source": [
    "#using rosenbrock function to define the nonlinear least squares objective\n",
    "\n",
    "F(x) = [x[1] - 1.0; 10 * (x[2] - x[1]^2)]\n",
    "x0 = [-1.2; 1.0]\n",
    "nls = ADNLSModel(F, x0, 2) # 2 nonlinear equations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d0679288",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10-element Vector{Float64}:\n",
       " 0.13556320842455183\n",
       " 0.532682955885541\n",
       " 0.175466572037158\n",
       " 0.8058867855949021\n",
       " 0.26168351948401436\n",
       " 0.36145613010115296\n",
       " 0.7163955140840705\n",
       " 0.2521181964978694\n",
       " 0.8595842558337334\n",
       " 0.06660440911282561"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rand(Float64, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5e5e5714",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LsqFit.LsqFitResult{Vector{Float64}, Vector{Float64}, Matrix{Float64}, Vector{Float64}}([0.9999999999988214, 0.9999999999976396], [-1.1786127629420662e-12, -3.219646771412954e-14], [0.9999999999960525 0.0; -19.999999999829377 10.000000000052196], true, Float64[])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fit = LsqFit.lmfit(F, [-1.2; 1.0], Float64[])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c65ddd05",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2×2 Matrix{Float64}:\n",
       "   1.0   0.0\n",
       " -20.0  10.0"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fit.jacobian"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "fc15e0f8",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m\u001b[1m   Resolving\u001b[22m\u001b[39m package versions...\n",
      "\u001b[32m\u001b[1m   Installed\u001b[22m\u001b[39m CodecBzip2 ─────── v0.7.2\n",
      "\u001b[32m\u001b[1m   Installed\u001b[22m\u001b[39m JuMP ───────────── v1.0.0\n",
      "\u001b[32m\u001b[1m   Installed\u001b[22m\u001b[39m MathOptInterface ─ v1.1.2\n",
      "\u001b[32m\u001b[1m    Updating\u001b[22m\u001b[39m `C:\\Users\\Kamlesh\\.julia\\environments\\v1.7\\Project.toml`\n",
      " \u001b[90m [4076af6c] \u001b[39m\u001b[92m+ JuMP v1.0.0\u001b[39m\n",
      "\u001b[32m\u001b[1m    Updating\u001b[22m\u001b[39m `C:\\Users\\Kamlesh\\.julia\\environments\\v1.7\\Manifest.toml`\n",
      " \u001b[90m [523fee87] \u001b[39m\u001b[92m+ CodecBzip2 v0.7.2\u001b[39m\n",
      " \u001b[90m [4076af6c] \u001b[39m\u001b[92m+ JuMP v1.0.0\u001b[39m\n",
      " \u001b[90m [b8f27783] \u001b[39m\u001b[92m+ MathOptInterface v1.1.2\u001b[39m\n",
      "\u001b[32m\u001b[1mPrecompiling\u001b[22m\u001b[39m project...\n",
      "\u001b[32m  ✓ \u001b[39m\u001b[90mCodecBzip2\u001b[39m\n",
      "\u001b[32m  ✓ \u001b[39m\u001b[90mMathOptInterface\u001b[39m\n",
      "\u001b[32m  ✓ \u001b[39mJuMP\n",
      "  3 dependencies successfully precompiled in 39 seconds (324 already precompiled)\n"
     ]
    }
   ],
   "source": [
    "Pkg.add(\"JuMP\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "9b749a74",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m\u001b[1m   Resolving\u001b[22m\u001b[39m package versions...\n",
      "\u001b[32m\u001b[1m   Installed\u001b[22m\u001b[39m NLPModelsJuMP ─ v0.10.1\n",
      "\u001b[32m\u001b[1m    Updating\u001b[22m\u001b[39m `C:\\Users\\Kamlesh\\.julia\\environments\\v1.7\\Project.toml`\n",
      " \u001b[90m [792afdf1] \u001b[39m\u001b[92m+ NLPModelsJuMP v0.10.1\u001b[39m\n",
      "\u001b[32m\u001b[1m    Updating\u001b[22m\u001b[39m `C:\\Users\\Kamlesh\\.julia\\environments\\v1.7\\Manifest.toml`\n",
      " \u001b[90m [792afdf1] \u001b[39m\u001b[92m+ NLPModelsJuMP v0.10.1\u001b[39m\n",
      "\u001b[32m\u001b[1mPrecompiling\u001b[22m\u001b[39m project...\n",
      "\u001b[32m  ✓ \u001b[39mNLPModelsJuMP\n",
      "  1 dependency successfully precompiled in 6 seconds (327 already precompiled)\n"
     ]
    }
   ],
   "source": [
    "Pkg.add(\"NLPModelsJuMP\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a67fd972",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "using JuMP, NLPModelsJuMP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "f9ede80c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MathOptNLSModel\n",
       "  Problem name: rosenbrock-nls\n",
       "   All variables: ████████████████████ 2      All constraints: ⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅ 0        All residuals: ████████████████████ 2     \n",
       "            free: ████████████████████ 2                 free: ⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅ 0               linear: ⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅ 0     \n",
       "           lower: ⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅ 0                lower: ⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅ 0            nonlinear: ████████████████████ 2     \n",
       "           upper: ⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅ 0                upper: ⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅ 0                 nnzj: ( 25.00% sparsity)   3     \n",
       "         low/upp: ⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅ 0              low/upp: ⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅ 0                 nnzh: ( 66.67% sparsity)   1     \n",
       "           fixed: ⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅ 0                fixed: ⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅ 0     \n",
       "          infeas: ⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅ 0               infeas: ⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅ 0     \n",
       "            nnzh: (  0.00% sparsity)   3               linear: ⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅ 0     \n",
       "                                                    nonlinear: ⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅ 0     \n",
       "                                                         nnzj: (------% sparsity)         \n",
       "\n",
       "  Counters:\n",
       "             obj: ⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅ 0                 grad: ⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅ 0                 cons: ⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅ 0     \n",
       "        cons_lin: ⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅ 0             cons_nln: ⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅ 0                 jcon: ⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅ 0     \n",
       "           jgrad: ⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅ 0                  jac: ⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅ 0              jac_lin: ⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅ 0     \n",
       "         jac_nln: ⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅ 0                jprod: ⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅ 0            jprod_lin: ⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅ 0     \n",
       "       jprod_nln: ⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅ 0               jtprod: ⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅ 0           jtprod_lin: ⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅ 0     \n",
       "      jtprod_nln: ⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅ 0                 hess: ⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅ 0                hprod: ⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅ 0     \n",
       "           jhess: ⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅ 0               jhprod: ⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅ 0             residual: ⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅ 0     \n",
       "    jac_residual: ⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅ 0       jprod_residual: ⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅ 0      jtprod_residual: ⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅ 0     \n",
       "   hess_residual: ⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅ 0       jhess_residual: ⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅ 0       hprod_residual: ⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅ 0     \n"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Model()\n",
    "x0 = [-1.2; 1.0]\n",
    "@variable(model, x[i=1:2], start=x0[i])\n",
    "\n",
    "@NLexpression(model, F1, x[1]-1)\n",
    "@NLexpression(model, F2, 10 * (x[2] - x[1]^2))\n",
    "\n",
    "nls = MathOptNLSModel(model, [F1, F2], name=\"rosenbrock-nls\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "66c1504c",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m\u001b[1m   Resolving\u001b[22m\u001b[39m package versions...\n",
      "\u001b[32m\u001b[1m   Installed\u001b[22m\u001b[39m SolverTools ──────── v0.8.0\n",
      "\u001b[32m\u001b[1m   Installed\u001b[22m\u001b[39m NLPModelsModifiers ─ v0.5.1\n",
      "\u001b[32m\u001b[1m   Installed\u001b[22m\u001b[39m JSOSolvers ───────── v0.7.6\n",
      "\u001b[32m\u001b[1m   Installed\u001b[22m\u001b[39m SolverCore ───────── v0.2.2\n",
      "\u001b[32m\u001b[1m   Installed\u001b[22m\u001b[39m Krylov ───────────── v0.7.13\n",
      "\u001b[32m\u001b[1m    Updating\u001b[22m\u001b[39m `C:\\Users\\Kamlesh\\.julia\\environments\\v1.7\\Project.toml`\n",
      " \u001b[90m [10dff2fc] \u001b[39m\u001b[92m+ JSOSolvers v0.7.6\u001b[39m\n",
      "\u001b[32m\u001b[1m    Updating\u001b[22m\u001b[39m `C:\\Users\\Kamlesh\\.julia\\environments\\v1.7\\Manifest.toml`\n",
      " \u001b[90m [10dff2fc] \u001b[39m\u001b[92m+ JSOSolvers v0.7.6\u001b[39m\n",
      " \u001b[90m [ba0b0d4f] \u001b[39m\u001b[92m+ Krylov v0.7.13\u001b[39m\n",
      " \u001b[90m [e01155f1] \u001b[39m\u001b[92m+ NLPModelsModifiers v0.5.1\u001b[39m\n",
      " \u001b[90m [ff4d7338] \u001b[39m\u001b[92m+ SolverCore v0.2.2\u001b[39m\n",
      " \u001b[90m [b5612192] \u001b[39m\u001b[92m+ SolverTools v0.8.0\u001b[39m\n",
      "\u001b[32m\u001b[1mPrecompiling\u001b[22m\u001b[39m project...\n",
      "\u001b[32m  ✓ \u001b[39m\u001b[90mSolverTools\u001b[39m\n",
      "\u001b[32m  ✓ \u001b[39m\u001b[90mSolverCore\u001b[39m\n",
      "\u001b[32m  ✓ \u001b[39m\u001b[90mNLPModelsModifiers\u001b[39m\n",
      "\u001b[32m  ✓ \u001b[39m\u001b[90mKrylov\u001b[39m\n",
      "\u001b[32m  ✓ \u001b[39mJSOSolvers\n",
      "  5 dependencies successfully precompiled in 4 seconds (328 already precompiled)\n"
     ]
    }
   ],
   "source": [
    "Pkg.add(\"JSOSolvers\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1a77b978",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Execution stats: first-order stationary\""
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "using JSOSolvers\n",
    "\n",
    "output = trunk(nls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "21d16aae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generic Execution stats\n",
      "  status: first-order stationary\n",
      "  objective value: 7.99609381573681e-20\n",
      "  primal feasibility: 0.0\n",
      "  dual feasibility: 8.942088019996678e-9\n",
      "  solution: [1.0  0.9999999999600098]\n",
      "  iterations: 19\n",
      "  elapsed time: 2.5859999656677246\n"
     ]
    }
   ],
   "source": [
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8ff8009f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2-element Vector{Float64}:\n",
       " 1.0\n",
       " 0.9999999999600098"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output.solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "79e5aeae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generic Execution stats\n",
      "  status: first-order stationary\n",
      "  objective value: 7.99609381573681e-20\n",
      "  primal feasibility: 0.0\n",
      "  dual feasibility: 8.942088019996678e-9\n",
      "  solution: [1.0  0.9999999999600098]\n",
      "  iterations: 19\n",
      "  elapsed time: 2.2360000610351562\n"
     ]
    }
   ],
   "source": [
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6ed6d1d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83b910fe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0db0e6e9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "278a073b",
   "metadata": {},
   "source": [
    "# Notations\n",
    "1. $\\underline{{N_I},{N_k}}$ - $N_I$ is the number of RF sequence pulses. This is also the number of snapshot images acquired during MRF. $N_k$ is the number of $k$-space sampling locations.<br><br> \n",
    "\n",
    "2. $\\underline{j}$ - refers to the $j^{\\text{th}}$ snapshot.<br><br>\n",
    "\n",
    "3. $\\underline{\\theta}$ - a vector of *true tissue* parameters on which the magnetization depends. The length of $\\theta$ is given as $n$ but is usually restricted to $3$ referring to the parameters $T_1, T_2$ relaxation times and the proton density, $\\rho$. <br><br>\n",
    "\n",
    "4. $\\underline{\\theta^*}$ - *reconstructed* parameters with MRF.<br><br>\n",
    "\n",
    "5. $\\underline{\\theta_1, \\theta_1^*}$ - contrast terms in true and reconstructed parameters respectively.<br><br>\n",
    "\n",
    "6. $\\underline{T_R, T_E, \\alpha, \\phi}$ - *experimental* parameters that refer to the repetition time ($T_R$), echo time ($T_E$), flip angle ($\\alpha$) and phase ($\\phi$).<br><br>\n",
    "\n",
    "7. $\\underline{\\boldsymbol{x, \\zeta}}$   - $\\boldsymbol x$ and $\\boldsymbol\\zeta$ refer to the coordinates in the spatial and $k$-space grid respectively. <br><br>\n",
    "\n",
    "8. $\\underline{M_j(\\theta)}$ - magnetization at the j<sup>th</sup> snapshot which is function of the tissue parameters $\\theta$. <br><br>\n",
    "\n",
    "9. $\\underline{\\boldsymbol \\kappa}$ - a vector of scaling factors; element $\\kappa_j$ refers to the scaling factor for the j<sup>th</sup> snapshot. <br><br>\n",
    "\n",
    "10. $\\underline{P_j(x), P(x)}$ - $P_j(x)$ refers to the point-spread function associated with j<sup>th</sup> snapshot and $P(x)$ refers to the average PSF given by $P(x)=\\frac{1}{N_I}\\sum\\limits_{j=1}^{N_I}P_j(x)$. <br><br>\n",
    "\n",
    "11. $\\underline{\\D M(\\theta)_j}$ - jacobian of $M_j(\\theta)$. The components of jacobian are denoted as $\\D M(\\theta)_{j;p}$. Note that the subscripts $p,q,r$ always refer to the position of elements in a matrix. If the matrix is a Jacobian then the position also refers to the parameter w.r.t which the partial derivative was taken. <br><br>\n",
    "\n",
    "12. $\\underline{\\widehat{f}}$ - denotes the Fourier transform of a function $f(.)$ \n",
    "\n",
    "In addition **boldfaced** letters are used to denote vectors. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "039e3536",
   "metadata": {},
   "source": [
    "# Error model\n",
    "\n",
    "$$\n",
    "\\Large\n",
    "\\boxed{\\theta_1^∗(x) = P \\circledast \\theta_1(x) + (\\RE\\,N)^{−1}(E_1(x) + E_2(x))}\n",
    "$$\n",
    "where\n",
    "$$\n",
    "\\begin{align*}\n",
    "E_{1;p}(x) &= \\RE\\, S^{(1,0)}_{\\text{resid};p} \\circledast 1(x)\\\\\n",
    "E_{2;p}(x) &= \\RE\\sum_q S^{(1,1)}_{\\text{resid};p,q} \\circledast \\theta_{1,q}(x)\n",
    "\\end{align*}\n",
    "$$\n",
    "\n",
    "We define the errors \n",
    "$$\n",
    "\\large\n",
    "\\begin{align*}\n",
    "&\\epsilon_1 = (\\RE\\,N)^{-1}E_1(x)\\\\\n",
    "&\\small\\text{Taking the Fourier transform on both sides we get}\\\\\n",
    "&\\Rightarrow \\widehat{\\epsilon_1}(k)_p = \\E_1(k)_p \\small\\text{ where, }\\quad \\E_1(k)_p =\\sum_r(\\RE\\,N)^{-1}_{p,r}\\widehat{S}^{(1,0)}_{resid;r}(k)\\\\\n",
    "\\\\\n",
    "&\\small\\text{and,}\\\\\n",
    "&\\epsilon_2 = (\\RE\\,N)^{-1}E_2(x)\\\\\n",
    "&\\small\\text{Taking the Fourier transform}\\\\\n",
    "&\\Rightarrow \\widehat{\\epsilon_2}(k)_p = \\sum_{q}\\E_2(k)_{p,q}\\widehat{\\theta_1}(k)_q \\small\\text{ where, }\\quad\n",
    "\\E_2(k)_{p,q} = \\sum_r (\\RE\\,N)^{-1}_{p,r}\\widehat{S}^{(1,1)}_{\\text{resid; }r,q}(k)\n",
    "\\end{align*}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18d57e58",
   "metadata": {},
   "source": [
    "**Supplementary equations**\n",
    "$$\n",
    "\\begin{align*}\n",
    "S^{(1,1)}_{\\text{resid};p,q}(x) &= \\sum^{N_I}_{j=1}(P_j (x) − P(x))\\overline{\\D M(\\theta_0)_{j;p}}\\D M(\\theta_0)_{j;q}\\\\\n",
    "S^{(1,0)}_{\\text{resid};p}(x) &= \\sum^{N_I}_{j=1}(P_j (x) − P(x))\\overline{\\D M(\\theta_0)_{j;p}}M(\\theta_0)_j\n",
    "\\end{align*}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a645581",
   "metadata": {},
   "source": [
    "# Assumption\n",
    "1. We assume that the magnetization $M_j(\\theta)$ is artifically rescaled by a scaling factor $\\kappa_j$ that changes the relative weight of each signal in the image. \n",
    "\\begin{align*}\n",
    "\\large\n",
    "M_j^{(new)}(\\theta) = \\kappa_j\\cdot M_j^{(old)}(\\theta)\n",
    "\\end{align*}\n",
    "2. ~Since $\\widehat{\\theta_1}(k)$ are tissue parameters of fixed size ($n$) and can assume random values. Therefore, $\\widehat{\\theta_1}(k)$ is assumed to be independent of $k$ and $q$~.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74295b78",
   "metadata": {},
   "source": [
    "### Compute $(\\RE \\,N)^{-1}$\n",
    "The elements of matrix $\\large N$ are found using\n",
    "$$\n",
    "\\begin{align*}\n",
    "N_{p,q} = \\sum_{j=1}^{N_I} \\overline{\\mathcal{D}M(\\theta_0)_{j;p}}\\mathcal{D}M(\\theta_0)_{j;q}\\\\\n",
    "\\end{align*}\n",
    "$$\n",
    "\n",
    "<!-- $$\n",
    "\\begin{align*}\n",
    "N_{1,1} &= \\sum_{j=1}^{N_I}\\kappa_j^2\\left.\\overline{\\frac{\\partial M_j}{\\partial T_1}}\\right\\rvert_{\\theta=\\theta_0}\\left.\\frac{\\partial M_j}{\\partial T_1}\\right\\rvert_{\\theta=\\theta_0}\\\\\n",
    "&= \\sum_{j=1}^{N_I}\\kappa_j^2\\left|\\frac{\\partial M_j}{\\partial T_1}\\right|_{\\theta=\\theta_0}^2\\\\\n",
    "N_{1,2} &= \\sum_{j=1}^{N_I}\\kappa_j^2\\left.\\overline{\\frac{\\partial M_j}{\\partial T_1}}\\right\\rvert_{\\theta=\\theta_0}\\left.\\frac{\\partial M_j}{\\partial T_2}\\right\\rvert_{\\theta=\\theta_0}\n",
    "\\end{align*}\n",
    "$$ \n",
    "Values for $N_{2,1}$ and $N_{2,2}$ can be found similarly.-->  \n",
    "\n",
    "For $3$ parameter case, the matrix expansion of $\\large N$ would give the following $3\\times3$ matrix\n",
    "$$\n",
    "\\large\n",
    "\\begin{equation*}\n",
    "N =\n",
    "\\begin{bmatrix}\n",
    "\\sum\\limits_{j=1}^{N_I}\\kappa_j^2\\left|\\frac{\\partial M_j}{\\partial T_1}\\right|_{\\theta=\\theta_0}^2 & \\sum\\limits\\limits_{j=1}^{N_I}\\kappa_j^2\\left.\\overline{\\frac{\\partial M_j}{\\partial T_1}}\\right\\rvert_{\\theta=\\theta_0}\\left.\\frac{\\partial M_j}{\\partial T_2}\\right\\rvert_{\\theta=\\theta_0} & \\sum\\limits_{j=1}^{N_I}\\kappa_j^2\\left.\\overline{\\frac{\\partial M_j}{\\partial T_1}}\\right\\rvert_{\\theta=\\theta_0}\\left.\\frac{\\partial M_j}{\\partial \\rho}\\right\\rvert_{\\theta=\\theta_0}\\\\\n",
    "\\sum\\limits_{j=1}^{N_I}\\kappa_j^2\\left.\\overline{\\frac{\\partial M_j}{\\partial T_2}}\\right\\rvert_{\\theta=\\theta_0}\\left.\\frac{\\partial M_j}{\\partial T_1}\\right\\rvert_{\\theta=\\theta_0} & \\sum\\limits_{j=1}^{N_I}\\kappa_j^2\\left|\\frac{\\partial M_j}{\\partial T_2}\\right|_{\\theta=\\theta_0}^2 & \\sum\\limits_{j=1}^{N_I}\\kappa_j^2\\left.\\overline{\\frac{\\partial M_j}{\\partial T_2}}\\right\\rvert_{\\theta=\\theta_0}\\left.\\frac{\\partial M_j}{\\partial \\rho}\\right\\rvert_{\\theta=\\theta_0}\\\\\n",
    "\\sum\\limits_{j=1}^{N_I}\\kappa_j^2\\left.\\overline{\\frac{\\partial M_j}{\\partial \\rho}}\\right\\rvert_{\\theta=\\theta_0}\\left.\\frac{\\partial M_j}{\\partial T_1}\\right\\rvert_{\\theta=\\theta_0} & \\sum\\limits_{j=1}^{N_I}\\kappa_j^2\\left.\\overline{\\frac{\\partial M_j}{\\partial \\rho}}\\right\\rvert_{\\theta=\\theta_0}\\left.\\frac{\\partial M_j}{\\partial T_2}\\right\\rvert_{\\theta=\\theta_0} & \\sum\\limits_{j=1}^{N_I}\\kappa_j^2\\left|\\frac{\\partial M_j}{\\partial \\rho}\\right|_{\\theta=\\theta_0}^2\n",
    "\\end{bmatrix}_{3\\times3}\n",
    "\\label{eq:N} \\tag{1}\n",
    "\\end{equation*}\n",
    "$$\n",
    "\n",
    "We then find $\\RE\\,N$ and compute its *matrix inverse* to get $(\\RE\\,N)^{-1}$\n",
    "\n",
    "<!-- ### Compute $\\widehat{S}^{(1,0)}_{resid;r}(\\zeta)$\n",
    "\n",
    "$$\n",
    "\\begin{align*}\n",
    "S^{(1,0)}_{\\text{resid};p}(x) &= \\sum^{N_I}_{j=1}(P_j (x) − P(x))\\overline{\\D M(\\theta_0)_{j;p}}M(\\theta_0)_j\\\\\n",
    "\\widehat{S}^{(1,0)}_{resid;r}(\\zeta) &=\\sum_{j=1}^{N_I}(\\widehat{P_j(0)}-\\widehat{P(0)})\\overline{\\D M(\\theta_0)_{j;r}}M(\\theta_0)_j\\\\\n",
    "\\end{align*}\n",
    "$$ -->\n",
    "\n",
    "### Compute $\\widehat{S}^{(1,1)}_{\\text{resid; }r,q}(\\zeta)$\n",
    "$$\n",
    "\\begin{align*}\n",
    "\\large\n",
    "S^{(1,1)}_{\\text{resid; }p,q}(x)&=\\sum_{j=1}^{N_I} (P_j(x)-P(x))\\overline{\\mathcal{D}M(\\theta_0)_{j;p}}\\mathcal{D}M(\\theta_0)_{j;q}\\\\\n",
    "\\large\n",
    "\\hat{S}^{(1,1)}_{\\text{resid; }p,q}(\\zeta) &= \\mathcal{F}\\left\\{\\sum_{j=1}^{N_I} (P_j(x)-P(x))\\overline{\\mathcal{D}M(\\theta_0)_{j;p}}\\mathcal{D}M(\\theta_0)_{j;q}\\right\\}(\\zeta)\\\\\n",
    "\\large\n",
    "\\Rightarrow\\hat{S}^{(1,1)}_{\\text{resid; }p,q}(\\zeta) &= \\sum_{j=1}^{N_I} \\left(\\widehat{P_j}(\\zeta)-\\widehat{P}(\\zeta)\\right)\\overline{\\mathcal{D}M(\\theta_0)_{j;p}}\\mathcal{D}M(\\theta_0)_{j;q} \n",
    "\\end{align*}\n",
    "$$\n",
    "\n",
    "For $3$ parameter case, the matrix $\\large S^{(1,1)}_{\\text{resid}}(\\zeta)$ would be given as\n",
    "$$\n",
    "\\begin{equation*}\n",
    "S^{(1,1)}_{\\text{resid}}(\\zeta) =\n",
    "\\begin{bmatrix}\n",
    "\\sum\\limits_{j=1}^{N_I}\\kappa_j^2\\left(\\widehat{P_j}(\\zeta)-\\widehat{P}(\\zeta)\\right)\\left|\\frac{\\partial M_j}{\\partial T_1}\\right|_{\\theta=\\theta_0}^2 & \\sum\\limits\\limits_{j=1}^{N_I}\\kappa_j^2\\left(\\widehat{P_j}(\\zeta)-\\widehat{P}(\\zeta)\\right)\\left.\\overline{\\frac{\\partial M_j}{\\partial T_1}}\\right\\rvert_{\\theta=\\theta_0}\\left.\\frac{\\partial M_j}{\\partial T_2}\\right\\rvert_{\\theta=\\theta_0} & \\sum\\limits_{j=1}^{N_I}\\kappa_j^2\\left(\\widehat{P_j}(\\zeta)-\\widehat{P}(\\zeta)\\right)\\left.\\overline{\\frac{\\partial M_j}{\\partial T_1}}\\right\\rvert_{\\theta=\\theta_0}\\left.\\frac{\\partial M_j}{\\partial \\rho}\\right\\rvert_{\\theta=\\theta_0}\\\\\n",
    "\\sum\\limits_{j=1}^{N_I}\\kappa_j^2\\left(\\widehat{P_j}(\\zeta)-\\widehat{P}(\\zeta)\\right)\\left.\\overline{\\frac{\\partial M_j}{\\partial T_2}}\\right\\rvert_{\\theta=\\theta_0}\\left.\\frac{\\partial M_j}{\\partial T_1}\\right\\rvert_{\\theta=\\theta_0} & \\sum\\limits_{j=1}^{N_I}\\kappa_j^2\\left(\\widehat{P_j}(\\zeta)-\\widehat{P}(\\zeta)\\right)\\left|\\frac{\\partial M_j}{\\partial T_2}\\right|_{\\theta=\\theta_0}^2 & \\sum\\limits_{j=1}^{N_I}\\kappa_j^2\\left(\\widehat{P_j}(\\zeta)-\\widehat{P}(\\zeta)\\right)\\left.\\overline{\\frac{\\partial M_j}{\\partial T_2}}\\right\\rvert_{\\theta=\\theta_0}\\left.\\frac{\\partial M_j}{\\partial \\rho}\\right\\rvert_{\\theta=\\theta_0}\\\\\n",
    "\\sum\\limits_{j=1}^{N_I}\\kappa_j^2\\left(\\widehat{P_j}(\\zeta)-\\widehat{P}(\\zeta)\\right)\\left.\\overline{\\frac{\\partial M_j}{\\partial \\rho}}\\right\\rvert_{\\theta=\\theta_0}\\left.\\frac{\\partial M_j}{\\partial T_1}\\right\\rvert_{\\theta=\\theta_0} & \\sum\\limits_{j=1}^{N_I}\\kappa_j^2\\left(\\widehat{P_j}(\\zeta)-\\widehat{P}(\\zeta)\\right)\\left.\\overline{\\frac{\\partial M_j}{\\partial \\rho}}\\right\\rvert_{\\theta=\\theta_0}\\left.\\frac{\\partial M_j}{\\partial T_2}\\right\\rvert_{\\theta=\\theta_0} & \\sum\\limits_{j=1}^{N_I}\\kappa_j^2\\left(\\widehat{P_j}(\\zeta)-\\widehat{P}(\\zeta)\\right)\\left|\\frac{\\partial M_j}{\\partial \\rho}\\right|_{\\theta=\\theta_0}^2\n",
    "\\end{bmatrix}_{3\\times3}\n",
    "\\end{equation*}\n",
    "$$\n",
    "\n",
    "\n",
    "### General form of  $\\widehat{\\epsilon_1}(\\zeta)$ terms\n",
    "\n",
    "$$\n",
    "\\begin{align*}\n",
    "&\\widehat{\\epsilon_1}(\\zeta)_p =\\quad \\E_1(\\zeta)_p =\\sum_r(\\RE\\,N)^{-1}_{p,r}\\widehat{S}^{(1,0)}_{resid;r}(\\zeta)\\delta(\\zeta)\\\\\n",
    "&\\text{where, }\\delta(\\zeta) \\text{ is the delta function which is 0 }\\forall \\zeta\\neq0\\\\\n",
    "&\\text{for } \\zeta=0 \\text{ , }\\delta(\\zeta)=1\\text{(assumed for simplicity) and the above expression reduces to}\\\\\n",
    "&\\large \\widehat{\\epsilon_1}(\\zeta)_p =\\sum_r(\\RE\\,N)^{-1}_{p,r}\\widehat{S}^{(1,0)}_{resid;r}(0)\\\\\n",
    "&\\text{where, }\\\\\n",
    "&\\small \\widehat{S}^{(1,0)}_{resid;r}(0)=\\sum_{j=1}^{N_I}(\\widehat{P_j(0)}-\\widehat{P(0)})\\overline{\\D M(\\theta_0)_{j;r}}M(\\theta_0)_j\n",
    "\\end{align*}\n",
    "$$\n",
    "\n",
    "Expanding the $\\widehat{S}^{(1,0)}_{resid;r}(0)$ for $r=1,2,3$ we get,\n",
    "$$\n",
    "\\begin{align*}\n",
    "\\widehat{S}^{(1,0)}_{resid;1}(0) &= \\sum_{j=1}^{N_I}\\kappa_j^2\\left(\\widehat{P_j(0)}-\\widehat{P(0)}\\right)\\left.\\frac{\\partial M_j}{\\partial T_1}\\right\\rvert_{\\theta=\\theta_0}M_j(\\theta_0)\\\\\n",
    "\\widehat{S}^{(1,0)}_{resid;2}(0) &= \\sum_{j=1}^{N_I}\\kappa_j^2\\left(\\widehat{P_j(0)}-\\widehat{P(0)}\\right)\\left.\\frac{\\partial M_j}{\\partial T_2}\\right\\rvert_{\\theta=\\theta_0}M_j(\\theta_0)\\\\\n",
    "\\widehat{S}^{(1,0)}_{resid;3}(0) &= \\sum_{j=1}^{N_I}\\kappa_j^2\\left(\\widehat{P_j(0)}-\\widehat{P(0)}\\right)\\left.\\frac{\\partial M_j}{\\partial \\rho}\\right\\rvert_{\\theta=\\theta_0}M_j(\\theta_0)\n",
    "\\end{align*}\n",
    "$$\n",
    "So the general form of  $\\widehat{\\epsilon_{1;p}}(\\zeta)$ is given by\n",
    "\n",
    "$$\n",
    "\\begin{equation*}\n",
    "\\widehat{\\epsilon_{1;p}}(\\boldsymbol\\kappa) = (\\RE\\,N)^{-1}_{p,1}\\widehat{S}^{(1,0)}_{resid;1}(0)+(\\RE\\,N)^{-1}_{p,2}\\widehat{S}^{(1,0)}_{resid;2}(0) + (\\RE\\,N)^{-1}_{p,3}\\widehat{S}^{(1,0)}_{resid;3}(0)\\\\\n",
    "\\end{equation*}\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\large\n",
    "\\begin{align*}\n",
    "\\Rightarrow\\widehat{\\epsilon_{1;p}}(\\boldsymbol\\kappa) &= (\\RE\\,N)^{-1}_{p,1}\\sum_{j=1}^{N_I}\\kappa_j^2\\left(\\widehat{P_j(0)}-\\widehat{P(0)}\\right)\\left.\\frac{\\partial M_j}{\\partial T_1}\\right\\rvert_{\\theta=\\theta_0}M_j(\\theta_0) \\\\ \n",
    "&+(\\RE\\,N)^{-1}_{p,2}\\sum_{j=1}^{N_I}\\kappa_j^2\\left(\\widehat{P_j(0)}-\\widehat{P(0)}\\right)\\left.\\frac{\\partial M_j}{\\partial T_2}\\right\\rvert_{\\theta=\\theta_0}M_j(\\theta_0) \\\\ \n",
    "&+(\\RE\\,N)^{-1}_{p,3}\\sum_{j=1}^{N_I}\\kappa_j^2\\left(\\widehat{P_j(0)}-\\widehat{P(0)}\\right)\\left.\\frac{\\partial M_j}{\\partial \\rho}\\right\\rvert_{\\theta=\\theta_0}M_j(\\theta_0)\n",
    "\\end{align*}\\tag{2}\n",
    "$$\n",
    "\n",
    "\n",
    "### General form of  $\\widehat{\\epsilon_2}(\\zeta)$ terms\n",
    "$$\n",
    "\\widehat{\\epsilon_{2;p}}(\\zeta) = \\sum_{q}\\E_{2}(\\zeta)_{p,q}\\widehat{\\theta_1}(\\zeta)_q \\small\\text{ where, }\\quad\n",
    "\\E_2(\\zeta)_{p,q} = \\sum_r (\\RE\\,N)^{-1}_{p,r}\\widehat{S}^{(1,1)}_{\\text{resid; }r,q}(\\zeta)\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\begin{align*}\n",
    "\\widehat{\\epsilon_{2;p}}(\\zeta) &= \\sum_q \\widehat{\\theta_{1;q}}(\\zeta)\\sum_r (\\RE\\,N)^{-1}_{p,r}\\widehat{S}^{(1,1)}_{\\text{resid; }r,q}(\\zeta)\\\\\n",
    "&= \\sum_q \\widehat{\\theta_{1;q}}(\\zeta)\\left\\{(\\RE\\,N)^{-1}_{p,1}\\widehat{S}^{(1,1)}_{\\text{resid; }1,q}(\\zeta)+(\\RE\\,N)^{-1}_{p,2}\\widehat{S}^{(1,1)}_{\\text{resid; }2,q}(\\zeta)+(\\RE\\,N)^{-1}_{p,3}\\widehat{S}^{(1,1)}_{\\text{resid; }3,q}(\\zeta)\\right\\}\n",
    "\\end{align*}\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\large\n",
    "\\begin{align*}\n",
    "\\Rightarrow\\widehat{\\epsilon_{2;p}}(\\boldsymbol{\\zeta,\\kappa}) &= \\widehat{\\theta_{1;1}}(\\zeta)\\left\\{(\\RE\\,N)^{-1}_{p,1}\\widehat{S}^{(1,1)}_{\\text{resid; }1,1}(\\zeta)+(\\RE\\,N)^{-1}_{p,2}\\widehat{S}^{(1,1)}_{\\text{resid; }2,1}(\\zeta)+(\\RE\\,N)^{-1}_{p,3}\\widehat{S}^{(1,1)}_{\\text{resid; }3,1}(\\zeta) \\right\\}\\\\\n",
    "&+ \\widehat{\\theta_{1;2}}(\\zeta)\\left\\{(\\RE\\,N)^{-1}_{p,1}\\widehat{S}^{(1,1)}_{\\text{resid; }1,2}(\\zeta)+(\\RE\\,N)^{-1}_{p,2}\\widehat{S}^{(1,1)}_{\\text{resid; }2,2}(\\zeta)+(\\RE\\,N)^{-1}_{p,3}\\widehat{S}^{(1,1)}_{\\text{resid; }3,2}(\\zeta) \\right\\}\\\\\n",
    "&+ \\widehat{\\theta_{1;3}}(\\zeta)\\left\\{(\\RE\\,N)^{-1}_{p,1}\\widehat{S}^{(1,1)}_{\\text{resid; }1,3}(\\zeta)+(\\RE\\,N)^{-1}_{p,2}\\widehat{S}^{(1,1)}_{\\text{resid; }2,3}(\\zeta)+(\\RE\\,N)^{-1}_{p,3}\\widehat{S}^{(1,1)}_{\\text{resid; }3,3}(\\zeta) \\right\\}\n",
    "\\end{align*}\\tag{3}\n",
    "$$\n",
    "\n",
    "**Note:** In the above equation, once we plug in the values from the $S^{(1,1)}_{\\text{resid}}(\\zeta)$ matrix, the $\\boldsymbol\\kappa$ dependence is evident. It is omitted for simpler notations. \n",
    "\n",
    "\n",
    "<!-- For a particular $k$-space cordinate $\\zeta$ and $n$ number of parameters the $(r,c)$ element of matrix $\\E_2$ is given as\n",
    "$$\n",
    "\\begin{align*}\\label{eq:E3}\n",
    "\\large\n",
    "\\boxed{\\E_2(\\zeta;\\boldsymbol\\kappa)_{r,c} = (\\RE\\,N)^{-1}_{r,1}\\hat{S}^{(1,1)}_{\\text{resid};1,c}(\\zeta) + (\\RE\\,N)^{-1}_{r,2}\\hat{S}^{(1,1)}_{\\text{resid};2,c}(\\zeta) \\ldots + (\\RE\\,N)^{-1}_{r,n}\\hat{S}^{(1,1)}_{\\text{resid};n,c}(\\zeta)}\n",
    "\\end{align*}\n",
    "$$ -->\n",
    "\n",
    "### Some observations\n",
    "- While $\\widehat{\\epsilon_{2;p}}(\\boldsymbol{\\zeta,\\kappa})$ depends on $\\boldsymbol{\\zeta,\\kappa}$, the $\\widehat{\\epsilon_{1;p}}(\\boldsymbol\\kappa)$ term depends only on $\\boldsymbol\\kappa$.\n",
    "- The terms $(\\RE\\,N)^{-1}_{p,1},(\\RE\\,N)^{-1}_{p,2},(\\RE\\,N)^{-1}_{p,3}$ form the p<sup>th</sup> row of matrix $(\\RE\\,N)^{-1}$. \n",
    "- Similarly, the terms $\\hat{S}^{(1,1)}_{\\text{resid};1,1}(\\zeta),\\hat{S}^{(1,1)}_{\\text{resid};2,1}(\\zeta),\\hat{S}^{(1,1)}_{\\text{resid};3,1}(\\zeta)$ form the 1<sup>st</sup> column of matrix $\\hat{S}^{(1,1)}_{\\text{resid}}(\\zeta)$. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81221728",
   "metadata": {},
   "source": [
    "## Minimizing the errors:\n",
    "\n",
    "We denote the overall error $\\widehat{\\epsilon_1}+\\widehat{\\epsilon_2}$ at each $k$-space location as  \n",
    "$$\n",
    "\\large\n",
    "\\G(\\boldsymbol\\zeta;\\boldsymbol\\kappa) = \n",
    "\\begin{bmatrix}\n",
    "\\G_1(\\boldsymbol{\\zeta;\\kappa})\\\\\n",
    "\\G_2(\\boldsymbol{\\zeta;\\kappa})\\\\\n",
    "\\G_3(\\boldsymbol{\\zeta;\\kappa})\n",
    "\\end{bmatrix}\n",
    "= \n",
    "\\begin{bmatrix}\n",
    "\\widehat{\\epsilon_{1;1}}(\\boldsymbol\\kappa)+\\widehat{\\epsilon_{2;1}}(\\boldsymbol{\\zeta,\\kappa})\\\\\n",
    "\\widehat{\\epsilon_{1;2}}(\\boldsymbol\\kappa)+\\widehat{\\epsilon_{2;2}}(\\boldsymbol{\\zeta,\\kappa})\\\\\n",
    "\\widehat{\\epsilon_{1;3}}(\\boldsymbol\\kappa)+\\widehat{\\epsilon_{2;3}}(\\boldsymbol{\\zeta,\\kappa})\n",
    "\\end{bmatrix}\n",
    "\\quad\\small\\text{substitute values from equation 2 & 3}\n",
    "$$\n",
    "\n",
    "**Few things to note** \n",
    "- $\\G_i(\\boldsymbol\\zeta;\\boldsymbol\\kappa)$ is the error in the specific parameter $i$. So $\\G_1(\\boldsymbol\\zeta;\\boldsymbol\\kappa)$ is the error in $T_1$.\n",
    "- $\\boldsymbol\\kappa = \\begin{bmatrix} \\kappa_1 & \\kappa_2 & \\dots &\\kappa_{N_I}\\end{bmatrix}$\n",
    "- $\\boldsymbol\\zeta = \\begin{bmatrix} \\zeta_1 & \\zeta_2 & \\dots & \\zeta_{N_k} \\end{bmatrix}$\n",
    "\n",
    "### Some thoughts on moving ahead\n",
    "- If we assume the errors are additive then the overall error $\\boldsymbol\\OG$ is given by\n",
    "$$\n",
    "\\large\n",
    "\\boldsymbol\\OG =\n",
    "\\begin{bmatrix}\n",
    "\\OG_1\\\\\n",
    "\\OG_2\\\\\n",
    "\\OG_3\n",
    "\\end{bmatrix}\n",
    "=\n",
    "\\begin{bmatrix}\n",
    "\\G_1(\\boldsymbol{\\zeta_1,\\kappa})+\\G_1(\\boldsymbol{\\zeta_2,\\kappa})+\\dots+\\G_1(\\boldsymbol{\\zeta_{N_k},\\kappa})\\\\\n",
    "\\G_2(\\boldsymbol{\\zeta_1,\\kappa})+\\G_2(\\boldsymbol{\\zeta_2,\\kappa})+\\dots+\\G_2(\\boldsymbol{\\zeta_{N_k},\\kappa})\\\\\n",
    "\\G_3(\\boldsymbol{\\zeta_1,\\kappa})+\\G_3(\\boldsymbol{\\zeta_2,\\kappa})+\\dots+\\G_3(\\boldsymbol{\\zeta_{N_k},\\kappa})\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "where, $\\OG_1=\\G_1(\\boldsymbol{\\zeta_1,\\kappa})+\\G_2(\\boldsymbol{\\zeta_2,\\kappa})+\\dots+\\G_{N_k}(\\boldsymbol{\\zeta_{N_k},\\kappa})$\n",
    "\n",
    "Ideally we want the errors to be zero for each parameter. So we can try to find a solution to $\\kappa$ for \n",
    "$$\n",
    "\\OG(\\boldsymbol{\\kappa})=\n",
    "\\begin{bmatrix}\n",
    "0\\\\\n",
    "0\\\\\n",
    "0\\\\\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "Taking the Jacobian of the overall error\n",
    "$$\n",
    "\\large\n",
    "\\begin{align*}\n",
    "\\D \\Gamma =\n",
    "\\begin{bmatrix}\n",
    "\\frac{\\partial\\OG_1}{\\partial \\kappa_1} & \\dots & \\frac{\\partial\\OG_1}{\\partial \\kappa_{N_I}}\\\\\n",
    "\\frac{\\partial\\OG_2}{\\partial \\kappa_1} & \\dots & \\frac{\\partial\\OG_2}{\\partial \\kappa_{N_I}}\\\\\n",
    "\\frac{\\partial\\OG_3}{\\partial \\kappa_1} & \\dots & \\frac{\\partial\\OG_3}{\\partial \\kappa_{N_I}}\n",
    "\\end{bmatrix}_{3\\times N_I}\n",
    "\\end{align*}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1391163f",
   "metadata": {},
   "source": [
    "## Solving non linear equations using [NLSolve.jl](https://github.com/JuliaNLSolvers/NLsolve.jl)\n",
    "\n",
    "Consider a vector valued function $F(x,y)$\n",
    "\n",
    "$F(x, y) = \\begin{bmatrix}(x+3)(y^3-7)+18 & \\sin(ye^x-1)\\end{bmatrix}$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e714f9af",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m\u001b[1m    Updating\u001b[22m\u001b[39m registry at `C:\\Users\\Kamlesh\\.julia\\registries\\General`\n",
      "\u001b[32m\u001b[1m    Updating\u001b[22m\u001b[39m git-repo `https://github.com/JuliaRegistries/General.git`\n",
      "\u001b[32m\u001b[1m   Resolving\u001b[22m\u001b[39m package versions...\n",
      "\u001b[32m\u001b[1m   Installed\u001b[22m\u001b[39m FiniteDiff ──── v2.11.0\n",
      "\u001b[32m\u001b[1m   Installed\u001b[22m\u001b[39m NLSolversBase ─ v7.8.2\n",
      "\u001b[32m\u001b[1m   Installed\u001b[22m\u001b[39m LineSearches ── v7.1.1\n",
      "\u001b[32m\u001b[1m   Installed\u001b[22m\u001b[39m NLsolve ─────── v4.5.1\n",
      "\u001b[32m\u001b[1m    Updating\u001b[22m\u001b[39m `C:\\Users\\Kamlesh\\.julia\\environments\\v1.7\\Project.toml`\n",
      " \u001b[90m [2774e3e8] \u001b[39m\u001b[92m+ NLsolve v4.5.1\u001b[39m\n",
      "\u001b[32m\u001b[1m    Updating\u001b[22m\u001b[39m `C:\\Users\\Kamlesh\\.julia\\environments\\v1.7\\Manifest.toml`\n",
      " \u001b[90m [6a86dc24] \u001b[39m\u001b[92m+ FiniteDiff v2.11.0\u001b[39m\n",
      " \u001b[90m [d3d80556] \u001b[39m\u001b[92m+ LineSearches v7.1.1\u001b[39m\n",
      " \u001b[90m [d41bc354] \u001b[39m\u001b[92m+ NLSolversBase v7.8.2\u001b[39m\n",
      " \u001b[90m [2774e3e8] \u001b[39m\u001b[92m+ NLsolve v4.5.1\u001b[39m\n",
      "\u001b[32m\u001b[1mPrecompiling\u001b[22m\u001b[39m project...\n",
      "\u001b[32m  ✓ \u001b[39m\u001b[90mFiniteDiff\u001b[39m\n",
      "\u001b[32m  ✓ \u001b[39m\u001b[90mNLSolversBase\u001b[39m\n",
      "\u001b[32m  ✓ \u001b[39m\u001b[90mLineSearches\u001b[39m\n",
      "\u001b[32m  ✓ \u001b[39mNLsolve\n",
      "  4 dependencies successfully precompiled in 12 seconds (316 already precompiled)\n"
     ]
    }
   ],
   "source": [
    "import Pkg\n",
    "Pkg.add(\"NLsolve\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ddcd942f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Results of Nonlinear Solver Algorithm\n",
       " * Algorithm: Trust-region with dogleg and autoscaling\n",
       " * Starting Point: [0.1, 1.2]\n",
       " * Zero: [-3.487552479724522e-16, 1.0000000000000002]\n",
       " * Inf-norm of residuals: 0.000000\n",
       " * Iterations: 4\n",
       " * Convergence: true\n",
       "   * |x - x'| < 0.0e+00: false\n",
       "   * |f(x)| < 1.0e-08: true\n",
       " * Function Calls (f): 5\n",
       " * Jacobian Calls (df/dx): 5"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "using NLsolve\n",
    "\n",
    "#computes the residuals of the nonlinear system,and stores them in a preallocated vector passed as first argument\n",
    "function f!(F, x)\n",
    "    F[1] = (x[1]+3)*(x[2]^3-7)+18\n",
    "    F[2] = sin(x[2]*exp(x[1])-1)\n",
    "end\n",
    "\n",
    "#computes the Jacobian of the system and stores it in a preallocated matrix passed as first argument. \n",
    "function j!(J, x)\n",
    "    J[1, 1] = x[2]^3-7\n",
    "    J[1, 2] = 3*x[2]^2*(x[1]+3)\n",
    "    u = exp(x[1])*cos(x[2]*exp(x[1])-1)\n",
    "    J[2, 1] = x[2]*u\n",
    "    J[2, 2] = u\n",
    "end\n",
    "\n",
    "nlsolve(f!, j!, [ 0.1; 1.2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb96c309",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91bbb536",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5ca77e52",
   "metadata": {},
   "source": [
    "## Some drafts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b709bf0d",
   "metadata": {},
   "source": [
    "### Objective functions: \n",
    "\n",
    "1. $$\\min \\underset{k,p,q}{\\max}\\E_2(k)_{p,q}$$ \n",
    "\n",
    "2. <u>*Least square formulation*</u>  \n",
    "Minimization in least square sense is given by\n",
    "$$\n",
    "\\large\n",
    "argmin_\\beta\\sum_{i=1}^m\\left[v_i -f(u_i;\\boldsymbol\\beta) \\right]^2\n",
    "$$\n",
    "\n",
    " In our case the residuals $v_i -f(u_i;\\boldsymbol\\beta)=\\E_2(\\zeta;\\boldsymbol\\kappa)_{r,c}$\n",
    "\n",
    "$$\n",
    "\\large\n",
    "\\therefore\\quad argmin_\\boldsymbol\\kappa\\sum_{r,c}\\left[ \\E_2(\\zeta;\\boldsymbol\\kappa)_{r,c}\\right]^2\n",
    "$$\n",
    "**To-Do:** Include $\\E_1$ terms as well.\n",
    "\n",
    "### Minimization\n",
    "\n",
    "For the above objective function, we construct a vector $E$ with elements as the individual $\\E_2$ terms found from equation $(2)$ and compute its jacobian $\\D E$. For the general case of $n=3$ parameters and a $k-$space grid of size $[m_1\\times m_2]$, $E$ and $\\D E$ are given as:\n",
    "\n",
    "$$\n",
    "\\begin{align*}\\label{eq:resid}\\tag{3}\n",
    "\\large\n",
    "E =\n",
    "\\begin{bmatrix}\n",
    "\\E_2(kx_1,ky_1)_{1,1}\\\\\n",
    "\\vdots\\\\\n",
    "\\E_2(kx_{m_1},ky_{m_2})_{3,1}\\\\\n",
    "\\E_2(kx_1,ky_1)_{1,2}\\\\\n",
    "\\vdots\\\\\n",
    "\\E_2(kx_{m_1},ky_{m_2})_{3,2}\\\\\n",
    "\\E_2(kx_1,ky_1)_{1,3}\\\\\n",
    "\\vdots\\\\\n",
    "\\E_2(kx_{m_1},ky_{m_2})_{3,3}\n",
    "\\end{bmatrix}\n",
    "\\end{align*}\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\large\n",
    "\\begin{align*}\n",
    "\\D E =\n",
    "\\begin{bmatrix}\n",
    "\\frac{\\partial\\E_2(kx_1,ky_1)_{1,1}}{\\partial \\kappa_1} & \\dots & \\frac{\\partial\\E_2(kx_1,ky_1)_{1,1}}{\\partial \\kappa_{N_I}}\\\\\n",
    "\\vdots & \\ddots & \\vdots\\\\\n",
    "\\frac{\\partial\\E_2(kx_{m_1},ky_{m_2})_{3,3}}{\\partial \\kappa_1} & \\dots & \\frac{\\partial\\E_2(kx_{m_1},ky_{m_2})_{3,3}}{\\partial \\kappa_{N_I}}\n",
    "\\end{bmatrix}\n",
    "\\end{align*}\n",
    "$$\n",
    "\n",
    "**Note** that $\\E_2$ has $3\\times3=9$ elements for each $k$-space coordinate. $\\therefore$ the length of vector $E$ is $9m_1m_2$ and the size of jacobian $\\D E$ is $9m_1m_2 \\times N_I$.  \n",
    "\n",
    "### Least square formulation for $\\large\\OG$\n",
    "Ideally we want the errors to be zero for each parameter. So we can minimize\n",
    "$$\n",
    "\\begin{align*}\n",
    "&\\left\\{(0-\\OG_1)^2+(0-\\OG_2)^2+(0-\\OG_3)^2\\right\\}\\\\\n",
    "\\\\\n",
    "&\\text{taking derivative w.r.t to } \\kappa\\text{ we get } N_I \\text{ gradient equations}\\\\\n",
    "\\\\\n",
    "\\Rightarrow&2\\left\\{\\OG_1\\frac{\\partial\\OG_1}{\\partial\\kappa_1} + \\OG_2\\frac{\\partial\\OG_2}{\\partial\\kappa_1} + \\OG_3\\frac{\\partial\\OG_3}{\\partial\\kappa_1}\\right\\}=0\\\\\n",
    "&2\\left\\{\\OG_1\\frac{\\partial\\OG_1}{\\partial\\kappa_2} + \\OG_2\\frac{\\partial\\OG_2}{\\partial\\kappa_2} + \\OG_3\\frac{\\partial\\OG_3}{\\partial\\kappa_2}\\right\\}=0\\\\\n",
    "&\\vdots\\\\\n",
    "&2\\left\\{\\OG_1\\frac{\\partial\\OG_1}{\\partial\\kappa_{N_I}} + \\OG_2\\frac{\\partial\\OG_2}{\\partial\\kappa_{N_I}} + \\OG_3\\frac{\\partial\\OG_3}{\\partial\\kappa_{N_I}}\\right\\}=0\n",
    "\\end{align*}\n",
    "$$\n",
    "\n",
    "Since the terms $\\OG_i\\frac{\\partial\\OG_i}{\\partial\\kappa_j}$ have degree $>1$ in $\\kappa_j$, the above system of equations are non-linear in $\\kappa_j$. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d04c535",
   "metadata": {},
   "source": [
    "## Guass-Newton algorithm (GNA)\n",
    "Given a set of $m$ empirical observations $(u_i,v_i)$ of independent and dependent variables, the parameter vector $\\boldsymbol\\beta$ of the *model curve* $\\mathbf{f}(\\boldsymbol{u;\\beta})$ is estimated using the iterative algorithm:\n",
    "\n",
    "> ### Algorithm\n",
    ">\n",
    "> 1. Start with an initial guess for $\\boldsymbol{\\beta}$.\n",
    "> 2. Compute the residual vector $\\left[\\mathbf {v} -\\mathbf {f} \\left({\\boldsymbol {u;\\beta}}\\right)\\right]\\quad\\forall(x,y)$\n",
    "> 3. Compute the Jacobian matrix $\\mathbf{J}$ using $\\boldsymbol{\\beta}$ and $x_i$.\n",
    "> 4. Solve for $\\boldsymbol {\\delta }$: $\\mathbf{J}^{\\mathrm {T}}\\mathbf {J} {\\boldsymbol {\\delta }}=\\mathbf {J} ^{\\mathrm {T} }\\left[\\mathbf {v} -\\mathbf {f} \\left({\\boldsymbol {u;\\beta }}\\right)\\right],$ where $\\boldsymbol {\\delta }$ is the parameter correction vector\n",
    "> 5. Update the parameter ${\\boldsymbol {\\beta }} = {\\boldsymbol {\\beta }} + \\boldsymbol {\\delta }$ and iterate till stopping criterion is reached.\n",
    "\n",
    "In our case:\n",
    "- The $\\mathbf{f}$ is ??\n",
    "- The residual vector in step 2 is given by equation $(3)$.\n",
    "- parameter $\\boldsymbol{\\beta}$ is the vector of scaling factors $\\boldsymbol\\kappa=[\\kappa_1,\\kappa_2,\\dots,\\kappa_{N_I}]$ \n",
    "- $u_i$ corresponds to a k-space point $(kx_i, ky_i)$.\n",
    "- what are the $v_i$??"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e65b29be",
   "metadata": {},
   "source": [
    "## Levenberg–Marquardt algorithm (LMA)\n",
    "> Change the equation in step 4 of GNA to ${\\displaystyle \\left[\\mathbf {J} ^{\\mathrm {T} }\\mathbf {J} +\\lambda \\operatorname {diag} \\left(\\mathbf {J} ^{\\mathrm {T} }\\mathbf {J} \\right)\\right]{\\boldsymbol {\\delta }}=\\mathbf {J} ^{\\mathrm {T} }\\left[\\mathbf {y} -\\mathbf {f} \\left({\\boldsymbol {\\beta }}\\right)\\right],}$ where $\\lambda$ is a damping factor."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff19879b",
   "metadata": {},
   "source": [
    "## Julia implementations \n",
    "\n",
    "### LMA\n",
    "The library [LsqFit.jl](https://julianlsolvers.github.io/LsqFit.jl/latest/getting_started/) implements the LMA algorithm using \n",
    "`curve_fit()` function. The call to the function looks like:\n",
    "```julia\n",
    "fit = curve_fit(model, [jacobian], x, y, [w,] p0; kwargs...)\n",
    "``` \n",
    "- `model`: function that takes two arguments (x, params)\n",
    "- `jacobian`: (optional) function that returns the Jacobian matrix of model\n",
    "- `x`: the independent variable\n",
    "- `y`: the dependent variable that constraints model\n",
    "- `w`: (optional) weight applied to the residual; can be a vector (of length(x) size or empty) or matrix (inverse covariance  matrix)\n",
    "- `p0`: initial guess of the model parameters\n",
    "- `kwargs`: tuning parameters for fitting, passed to levenberg_marquardt, such as maxIter, show_trace or lower and upper bounds\n",
    "\n",
    "If a Jacobian is not provided, the central finite difference scheme is used to approximate the Jacobian. It is also possible to use forward mode automatic differentiation as implemented in [ForwardDiff.jl](https://juliadiff.org/ForwardDiff.jl/stable/) by using the `autodiff=:forwarddiff` keyword.\n",
    "\n",
    "### BFGS\n",
    "The library [Optim.jl](https://julianlsolvers.github.io/Optim.jl/stable/#user/minimization/) has the option to use BFGS algorithm.\n",
    "```julia\n",
    "Optim.minimizer(optimize(f, initial_x, BFGS(); autodiff = :forward))\n",
    "``` "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79a6a682",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c49b6399",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff5a3a6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from importlib.metadata import version\n",
    "# from platform import python_version\n",
    "\n",
    "# print(python_version())\n",
    "# version('numpy')\n",
    "# import numpy as np\n",
    "# x = np.array([1, 2.5, 3.5, 4, 5, 7, 8.5])\n",
    "# x[:,np.newaxis]**[0,2]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d20a9f1e",
   "metadata": {},
   "source": [
    "## Cross talk error term $\\mathcal{E}_2$\n",
    "\\begin{align*}\n",
    "\\Large\n",
    "\\mathcal{E}_2(k)_{p,q} = \\sum_r (\\RE\\,N)^{-1}_{p,r}\\hat{S}^{(1,1)}_{\\text{resid; }r,q}(k)\n",
    "\\end{align*}\n",
    "$\\mathcal{E}_2(k)_{p,q}$ is a $N_p\\times N_p$ matrix for each $k$\n",
    "\n",
    "### For $n=3$ parameter case ($T_1, T_2$ and $\\rho$)  \n",
    "\n",
    "\n",
    "So we have $3\\times3=9$ entries for each $k$-space coordinate. For a $k-$space grid of $[m_1\\times m_2]$, we construct the vector $E$ with elements as the elements of the $\\mathcal{E}$ matrix. Note that vector $E$ has a length of $9m_1m_2$.\n",
    "$$\n",
    "\\begin{align*}\n",
    "E =\n",
    "\\begin{bmatrix}\n",
    "\\mathcal{E}_2(kx_1,ky_1)_{1,1}\\\\\n",
    "\\vdots\\\\\n",
    "\\mathcal{E}_2(kx_{m_1},ky_{m_2})_{1,1}\\\\\n",
    "\\mathcal{E}_2(kx_1,ky_1)_{2,1}\\\\\n",
    "\\vdots\\\\\n",
    "\\mathcal{E}_2(kx_{m_1},ky_{m_2})_{2,1}\\\\\n",
    "\\mathcal{E}_2(kx_1,ky_1)_{3,1}\\\\\n",
    "\\vdots\\\\\n",
    "\\mathcal{E}_2(kx_{m_1},ky_{m_2})_{3,1}\\\\\n",
    "\\mathcal{E}_2(kx_1,ky_1)_{1,2}\\\\\n",
    "\\vdots\\\\\n",
    "\\mathcal{E}_2(kx_{m_1},ky_{m_2})_{1,2}\\\\\n",
    "\\mathcal{E}_2(kx_1,ky_1)_{2,2}\\\\\n",
    "\\vdots\\\\\n",
    "\\mathcal{E}_2(kx_{m_1},ky_{m_2})_{2,2}\\\\\n",
    "\\mathcal{E}_2(kx_1,ky_1)_{3,2}\\\\\n",
    "\\vdots\\\\\n",
    "\\mathcal{E}_2(kx_{m_1},ky_{m_2})_{3,2}\\\\\n",
    "\\mathcal{E}_2(kx_1,ky_1)_{1,3}\\\\\n",
    "\\vdots\\\\\n",
    "\\mathcal{E}_2(kx_{m_1},ky_{m_2})_{1,3}\\\\\n",
    "\\mathcal{E}_2(kx_1,ky_1)_{2,3}\\\\\n",
    "\\vdots\\\\\n",
    "\\mathcal{E}_2(kx_{m_1},ky_{m_2})_{2,3}\\\\\n",
    "\\mathcal{E}_2(kx_1,ky_1)_{3,3}\\\\\n",
    "\\vdots\\\\\n",
    "\\mathcal{E}_2(kx_{m_1},ky_{m_2})_{3,3}\n",
    "\\end{bmatrix}\n",
    "\\end{align*}\n",
    "$$\n",
    "*We now try to minimize the $\\left\\lVert E \\right\\rVert^2$, where $\\left\\lVert . \\right\\rVert$ is the $\\ell_2$ norm*"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.7.2",
   "language": "julia",
   "name": "julia-1.7"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
