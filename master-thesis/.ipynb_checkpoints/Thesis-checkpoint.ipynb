{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9efc991b",
   "metadata": {},
   "source": [
    "$\\newcommand{\\RE}{\\mathrm{Re}}$\n",
    "$\\newcommand{\\IM}{\\mathrm{Im}}$\n",
    "$\\newcommand{\\D}{\\mathcal{D}}$\n",
    "$\\newcommand{\\E}{\\mathcal{E}}$\n",
    "$\\newcommand{\\G}{\\Gamma}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1fd375d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.19.3'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from importlib.metadata import version\n",
    "from platform import python_version\n",
    "\n",
    "print(python_version())\n",
    "version('numpy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ea9700bf",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0f4afe47",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1. , 2.5, 3.5, 4. , 5. , 7. , 8.5])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = np.array([1, 2.5, 3.5, 4, 5, 7, 8.5])\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8d4312eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.  ,  1.  ],\n",
       "       [ 1.  ,  6.25],\n",
       "       [ 1.  , 12.25],\n",
       "       [ 1.  , 16.  ],\n",
       "       [ 1.  , 25.  ],\n",
       "       [ 1.  , 49.  ],\n",
       "       [ 1.  , 72.25]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[:,np.newaxis]**[0,2]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "278a073b",
   "metadata": {},
   "source": [
    "# Notations\n",
    "1. $\\underline{N_I}$ - the number of RF sequence pulses. This is also the number of snapshot images acquired during MRF.<br><br> \n",
    "\n",
    "2. $\\underline{j}$ - refers to the $j^{\\text{th}}$ snapshot.<br><br>\n",
    "\n",
    "3. $\\underline{\\theta}$ - a vector of *true tissue* parameters on which the magnetization depends. The length of $\\theta$ is given as $n$ but is usually restricted to $3$ referring to the parameters $T_1, T_2$ relaxation times and the proton density, $\\rho$. <br><br>\n",
    "\n",
    "4. $\\underline{\\theta^*}$ - *reconstructed* parameters with MRF.<br><br>\n",
    "\n",
    "5. $\\underline{\\theta_1, \\theta_1^*}$ - contrast terms in true and reconstructed parameters respectively.<br><br>\n",
    "\n",
    "6. $\\underline{T_R, T_E, \\alpha, \\phi}$ - *experimental* parameters that refer to the repetition time ($T_R$), echo time ($T_E$), flip angle ($\\alpha$) and phase ($\\phi$).<br><br>\n",
    "\n",
    "7. $\\underline{x, \\zeta}$   - $x$ and $\\zeta$ refer to the coordinates in the spatial and $k$-space grid respectively. <br><br>\n",
    "\n",
    "8. $\\underline{M_j(\\theta)}$ - magnetization at the j<sup>th</sup> snapshot which is function of the tissue parameters $\\theta$. <br><br>\n",
    "\n",
    "9. $\\underline{\\boldsymbol \\kappa}$ - a vector of scaling factors; element $\\kappa_j$ refers to the scaling factor for the j<sup>th</sup> snapshot. <br><br>\n",
    "\n",
    "10. $\\underline{P_j(x), P(x)}$ - $P_j(x)$ refers to the point-spread function associated with j<sup>th</sup> snapshot and $P(x)$ refers to the average PSF given by $P(x)=\\frac{1}{N_I}\\sum\\limits_{j=1}^{N_I}P_j(x)$. <br><br>\n",
    "\n",
    "11. $\\underline{\\D M(\\theta)_j}$ - jacobian of $M_j(\\theta)$. The components of jacobian are denoted as $\\D M(\\theta)_{j;p}$. Note that the subscripts $p,q,r$ always refer to the position of elements in a matrix. If the matrix is a Jacobian then the position also refers to the parameter w.r.t which the partial derivative was taken. <br><br>\n",
    "\n",
    "12. $\\underline{\\widehat{f}}$ - denotes the Fourier transform of a function $f(.)$ "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "039e3536",
   "metadata": {},
   "source": [
    "# Error model\n",
    "\n",
    "$$\n",
    "\\Large\n",
    "\\boxed{\\theta_1^∗(x) = P \\circledast \\theta_1(x) + (\\RE\\,N)^{−1}(E_1(x) + E_2(x))}\n",
    "$$\n",
    "where\n",
    "$$\n",
    "\\begin{align*}\n",
    "E_{1;p}(x) &= \\RE\\, S^{(1,0)}_{\\text{resid};p} \\circledast 1(x)\\\\\n",
    "E_{2;p}(x) &= \\RE\\sum_q S^{(1,1)}_{\\text{resid};p,q} \\circledast \\theta_{1,q}(x)\n",
    "\\end{align*}\n",
    "$$\n",
    "\n",
    "We define the errors \n",
    "$$\n",
    "\\large\n",
    "\\begin{align*}\n",
    "&\\epsilon_1 = (\\RE\\,N)^{-1}E_1(x)\\\\\n",
    "&\\small\\text{Taking the Fourier transform on both sides we get}\\\\\n",
    "&\\Rightarrow \\widehat{\\epsilon_1}(k)_p = \\E_1(k)_p \\small\\text{ where, }\\quad \\E_1(k)_p =\\sum_r(\\RE\\,N)^{-1}_{p,r}\\widehat{S}^{(1,0)}_{resid;r}(k)\\\\\n",
    "\\\\\n",
    "&\\small\\text{and,}\\\\\n",
    "&\\epsilon_2 = (\\RE\\,N)^{-1}E_2(x)\\\\\n",
    "&\\small\\text{Taking the Fourier transform}\\\\\n",
    "&\\Rightarrow \\widehat{\\epsilon_2}(k)_p = \\sum_{q}\\E_2(k)_{p,q}\\widehat{\\theta_1}(k)_q \\small\\text{ where, }\\quad\n",
    "\\E_2(k)_{p,q} = \\sum_r (\\RE\\,N)^{-1}_{p,r}\\widehat{S}^{(1,1)}_{\\text{resid; }r,q}(k)\n",
    "\\end{align*}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18d57e58",
   "metadata": {},
   "source": [
    "**Supplementary equations**\n",
    "$$\n",
    "\\begin{align*}\n",
    "S^{(1,1)}_{\\text{resid};p,q}(x) &= \\sum^{N_I}_{j=1}(P_j (x) − P(x))\\overline{\\D M(\\theta_0)_{j;p}}\\D M(\\theta_0)_{j;q}\\\\\n",
    "S^{(1,0)}_{\\text{resid};p}(x) &= \\sum^{N_I}_{j=1}(P_j (x) − P(x))\\overline{\\D M(\\theta_0)_{j;p}}M(\\theta_0)_j\n",
    "\\end{align*}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a645581",
   "metadata": {},
   "source": [
    "# Assumption\n",
    "1. We assume that the magnetization $M_j(\\theta)$ is artifically rescaled by a scaling factor $\\kappa_j$ that changes the relative weight of each signal in the image. \n",
    "\\begin{align*}\n",
    "\\large\n",
    "M_j^{(new)}(\\theta) = \\kappa_j\\cdot M_j^{(old)}(\\theta)\n",
    "\\end{align*}\n",
    "2. ~Since $\\widehat{\\theta_1}(k)$ are tissue parameters of fixed size ($n$) and can assume random values. Therefore, $\\widehat{\\theta_1}(k)$ is assumed to be independent of $k$ and $q$~.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74295b78",
   "metadata": {},
   "source": [
    "### Compute $(\\RE \\,N)^{-1}$\n",
    "The elements of matrix $\\large N$ are found using\n",
    "$$\n",
    "\\begin{align*}\n",
    "N_{p,q} = \\sum_{j=1}^{N_I} \\overline{\\mathcal{D}M(\\theta_0)_{j;p}}\\mathcal{D}M(\\theta_0)_{j;q}\\\\\n",
    "\\end{align*}\n",
    "$$\n",
    "\n",
    "<!-- $$\n",
    "\\begin{align*}\n",
    "N_{1,1} &= \\sum_{j=1}^{N_I}\\kappa_j^2\\left.\\overline{\\frac{\\partial M_j}{\\partial T_1}}\\right\\rvert_{\\theta=\\theta_0}\\left.\\frac{\\partial M_j}{\\partial T_1}\\right\\rvert_{\\theta=\\theta_0}\\\\\n",
    "&= \\sum_{j=1}^{N_I}\\kappa_j^2\\left|\\frac{\\partial M_j}{\\partial T_1}\\right|_{\\theta=\\theta_0}^2\\\\\n",
    "N_{1,2} &= \\sum_{j=1}^{N_I}\\kappa_j^2\\left.\\overline{\\frac{\\partial M_j}{\\partial T_1}}\\right\\rvert_{\\theta=\\theta_0}\\left.\\frac{\\partial M_j}{\\partial T_2}\\right\\rvert_{\\theta=\\theta_0}\n",
    "\\end{align*}\n",
    "$$ \n",
    "Values for $N_{2,1}$ and $N_{2,2}$ can be found similarly.-->  \n",
    "\n",
    "For $n=3$ parameter case, the matrix expansion of $\\large N$ would give the following $3\\times3$ matrix\n",
    "$$\n",
    "\\large\n",
    "\\begin{equation*}\n",
    "N =\n",
    "\\begin{bmatrix}\n",
    "\\sum\\limits_{j=1}^{N_I}\\kappa_j^2\\left|\\frac{\\partial M_j}{\\partial T_1}\\right|_{\\theta=\\theta_0}^2 & \\sum\\limits\\limits_{j=1}^{N_I}\\kappa_j^2\\left.\\overline{\\frac{\\partial M_j}{\\partial T_1}}\\right\\rvert_{\\theta=\\theta_0}\\left.\\frac{\\partial M_j}{\\partial T_2}\\right\\rvert_{\\theta=\\theta_0} & \\sum\\limits_{j=1}^{N_I}\\kappa_j^2\\left.\\overline{\\frac{\\partial M_j}{\\partial T_1}}\\right\\rvert_{\\theta=\\theta_0}\\left.\\frac{\\partial M_j}{\\partial \\rho}\\right\\rvert_{\\theta=\\theta_0}\\\\\n",
    "\\sum\\limits_{j=1}^{N_I}\\kappa_j^2\\left.\\overline{\\frac{\\partial M_j}{\\partial T_2}}\\right\\rvert_{\\theta=\\theta_0}\\left.\\frac{\\partial M_j}{\\partial T_1}\\right\\rvert_{\\theta=\\theta_0} & \\sum\\limits_{j=1}^{N_I}\\kappa_j^2\\left|\\frac{\\partial M_j}{\\partial T_2}\\right|_{\\theta=\\theta_0}^2 & \\sum\\limits_{j=1}^{N_I}\\kappa_j^2\\left.\\overline{\\frac{\\partial M_j}{\\partial T_2}}\\right\\rvert_{\\theta=\\theta_0}\\left.\\frac{\\partial M_j}{\\partial \\rho}\\right\\rvert_{\\theta=\\theta_0}\\\\\n",
    "\\sum\\limits_{j=1}^{N_I}\\kappa_j^2\\left.\\overline{\\frac{\\partial M_j}{\\partial \\rho}}\\right\\rvert_{\\theta=\\theta_0}\\left.\\frac{\\partial M_j}{\\partial T_1}\\right\\rvert_{\\theta=\\theta_0} & \\sum\\limits_{j=1}^{N_I}\\kappa_j^2\\left.\\overline{\\frac{\\partial M_j}{\\partial \\rho}}\\right\\rvert_{\\theta=\\theta_0}\\left.\\frac{\\partial M_j}{\\partial T_2}\\right\\rvert_{\\theta=\\theta_0} & \\sum\\limits_{j=1}^{N_I}\\kappa_j^2\\left|\\frac{\\partial M_j}{\\partial \\rho}\\right|_{\\theta=\\theta_0}^2\n",
    "\\end{bmatrix}\n",
    "\\label{eq:N} \\tag{1}\n",
    "\\end{equation*}\n",
    "$$\n",
    "\n",
    "We then find $\\RE\\,N$ and compute its *matrix inverse* to get $(\\RE\\,N)^{-1}$\n",
    "\n",
    "<!-- ### Compute $\\widehat{S}^{(1,0)}_{resid;r}(\\zeta)$\n",
    "\n",
    "$$\n",
    "\\begin{align*}\n",
    "S^{(1,0)}_{\\text{resid};p}(x) &= \\sum^{N_I}_{j=1}(P_j (x) − P(x))\\overline{\\D M(\\theta_0)_{j;p}}M(\\theta_0)_j\\\\\n",
    "\\widehat{S}^{(1,0)}_{resid;r}(\\zeta) &=\\sum_{j=1}^{N_I}(\\widehat{P_j(0)}-\\widehat{P(0)})\\overline{\\D M(\\theta_0)_{j;r}}M(\\theta_0)_j\\\\\n",
    "\\end{align*}\n",
    "$$ -->\n",
    "\n",
    "### Compute $\\widehat{S}^{(1,1)}_{\\text{resid; }r,q}(\\zeta)$\n",
    "$$\n",
    "\\begin{align*}\n",
    "\\large\n",
    "S^{(1,1)}_{\\text{resid; }p,q}(x)&=\\sum_{j=1}^{N_I} (P_j(x)-P(x))\\overline{\\mathcal{D}M(\\theta_0)_{j;p}}\\mathcal{D}M(\\theta_0)_{j;q}\\\\\n",
    "\\large\n",
    "\\hat{S}^{(1,1)}_{\\text{resid; }p,q}(\\zeta) &= \\mathcal{F}\\left\\{\\sum_{j=1}^{N_I} (P_j(x)-P(x))\\overline{\\mathcal{D}M(\\theta_0)_{j;p}}\\mathcal{D}M(\\theta_0)_{j;q}\\right\\}(\\zeta)\\\\\n",
    "\\large\n",
    "\\Rightarrow\\hat{S}^{(1,1)}_{\\text{resid; }p,q}(\\zeta) &= \\sum_{j=1}^{N_I} \\left(\\widehat{P_j}(\\zeta)-\\widehat{P}(\\zeta)\\right)\\overline{\\mathcal{D}M(\\theta_0)_{j;p}}\\mathcal{D}M(\\theta_0)_{j;q} \n",
    "\\end{align*}\n",
    "$$\n",
    "\n",
    "For $n=3$ parameter case, the matrix $\\large S^{(1,1)}_{\\text{resid}}(\\zeta)$ would be given as\n",
    "$$\n",
    "\\begin{equation*}\n",
    "S^{(1,1)}_{\\text{resid}}(\\zeta) =\n",
    "\\begin{bmatrix}\n",
    "\\sum\\limits_{j=1}^{N_I}\\kappa_j^2\\left(\\widehat{P_j}(\\zeta)-\\widehat{P}(\\zeta)\\right)\\left|\\frac{\\partial M_j}{\\partial T_1}\\right|_{\\theta=\\theta_0}^2 & \\sum\\limits\\limits_{j=1}^{N_I}\\kappa_j^2\\left(\\widehat{P_j}(\\zeta)-\\widehat{P}(\\zeta)\\right)\\left.\\overline{\\frac{\\partial M_j}{\\partial T_1}}\\right\\rvert_{\\theta=\\theta_0}\\left.\\frac{\\partial M_j}{\\partial T_2}\\right\\rvert_{\\theta=\\theta_0} & \\sum\\limits_{j=1}^{N_I}\\kappa_j^2\\left(\\widehat{P_j}(\\zeta)-\\widehat{P}(\\zeta)\\right)\\left.\\overline{\\frac{\\partial M_j}{\\partial T_1}}\\right\\rvert_{\\theta=\\theta_0}\\left.\\frac{\\partial M_j}{\\partial \\rho}\\right\\rvert_{\\theta=\\theta_0}\\\\\n",
    "\\sum\\limits_{j=1}^{N_I}\\kappa_j^2\\left(\\widehat{P_j}(\\zeta)-\\widehat{P}(\\zeta)\\right)\\left.\\overline{\\frac{\\partial M_j}{\\partial T_2}}\\right\\rvert_{\\theta=\\theta_0}\\left.\\frac{\\partial M_j}{\\partial T_1}\\right\\rvert_{\\theta=\\theta_0} & \\sum\\limits_{j=1}^{N_I}\\kappa_j^2\\left(\\widehat{P_j}(\\zeta)-\\widehat{P}(\\zeta)\\right)\\left|\\frac{\\partial M_j}{\\partial T_2}\\right|_{\\theta=\\theta_0}^2 & \\sum\\limits_{j=1}^{N_I}\\kappa_j^2\\left(\\widehat{P_j}(\\zeta)-\\widehat{P}(\\zeta)\\right)\\left.\\overline{\\frac{\\partial M_j}{\\partial T_2}}\\right\\rvert_{\\theta=\\theta_0}\\left.\\frac{\\partial M_j}{\\partial \\rho}\\right\\rvert_{\\theta=\\theta_0}\\\\\n",
    "\\sum\\limits_{j=1}^{N_I}\\kappa_j^2\\left(\\widehat{P_j}(\\zeta)-\\widehat{P}(\\zeta)\\right)\\left.\\overline{\\frac{\\partial M_j}{\\partial \\rho}}\\right\\rvert_{\\theta=\\theta_0}\\left.\\frac{\\partial M_j}{\\partial T_1}\\right\\rvert_{\\theta=\\theta_0} & \\sum\\limits_{j=1}^{N_I}\\kappa_j^2\\left(\\widehat{P_j}(\\zeta)-\\widehat{P}(\\zeta)\\right)\\left.\\overline{\\frac{\\partial M_j}{\\partial \\rho}}\\right\\rvert_{\\theta=\\theta_0}\\left.\\frac{\\partial M_j}{\\partial T_2}\\right\\rvert_{\\theta=\\theta_0} & \\sum\\limits_{j=1}^{N_I}\\kappa_j^2\\left(\\widehat{P_j}(\\zeta)-\\widehat{P}(\\zeta)\\right)\\left|\\frac{\\partial M_j}{\\partial \\rho}\\right|_{\\theta=\\theta_0}^2\n",
    "\\end{bmatrix}\n",
    "\\end{equation*}\n",
    "$$\n",
    "\n",
    "\n",
    "### General form of  $\\widehat{\\epsilon_1}(\\zeta)$ terms\n",
    "\n",
    "$$\n",
    "\\begin{align*}\n",
    "&\\widehat{\\epsilon_1}(\\zeta)_p =\\quad \\E_1(\\zeta)_p =\\sum_r(\\RE\\,N)^{-1}_{p,r}\\widehat{S}^{(1,0)}_{resid;r}(\\zeta)\\delta(\\zeta)\\\\\n",
    "&\\text{where, }\\delta(\\zeta) \\text{ is the delta function which is 0 }\\forall \\zeta\\neq0\\\\\n",
    "&\\text{for } \\zeta=0 \\text{ , }\\delta(\\zeta)=1\\text{(assumed for simplicity) and the above expression reduces to}\\\\\n",
    "&\\large \\widehat{\\epsilon_1}(\\zeta)_p =\\sum_r(\\RE\\,N)^{-1}_{p,r}\\widehat{S}^{(1,0)}_{resid;r}(0)\\\\\n",
    "&\\text{where, }\\\\\n",
    "&\\small \\widehat{S}^{(1,0)}_{resid;r}(0)=\\sum_{j=1}^{N_I}(\\widehat{P_j(0)}-\\widehat{P(0)})\\overline{\\D M(\\theta_0)_{j;r}}M(\\theta_0)_j\n",
    "\\end{align*}\n",
    "$$\n",
    "\n",
    "Expanding the $\\widehat{S}^{(1,0)}_{resid;r}(0)$ for $r=1,2,3$ we get,\n",
    "$$\n",
    "\\begin{align*}\n",
    "\\widehat{S}^{(1,0)}_{resid;1}(0) &= \\sum_{j=1}^{N_I}\\kappa_j^2\\left(\\widehat{P_j(0)}-\\widehat{P(0)}\\right)\\left.\\frac{\\partial M_j}{\\partial T_1}\\right\\rvert_{\\theta=\\theta_0}M_j(\\theta_0)\\\\\n",
    "\\widehat{S}^{(1,0)}_{resid;2}(0) &= \\sum_{j=1}^{N_I}\\kappa_j^2\\left(\\widehat{P_j(0)}-\\widehat{P(0)}\\right)\\left.\\frac{\\partial M_j}{\\partial T_2}\\right\\rvert_{\\theta=\\theta_0}M_j(\\theta_0)\\\\\n",
    "\\widehat{S}^{(1,0)}_{resid;3}(0) &= \\sum_{j=1}^{N_I}\\kappa_j^2\\left(\\widehat{P_j(0)}-\\widehat{P(0)}\\right)\\left.\\frac{\\partial M_j}{\\partial \\rho}\\right\\rvert_{\\theta=\\theta_0}M_j(\\theta_0)\n",
    "\\end{align*}\n",
    "$$\n",
    "So the general form of  $\\widehat{\\epsilon_{1;p}}(\\zeta)$ is given by\n",
    "\n",
    "$$\n",
    "\\begin{equation*}\n",
    "\\widehat{\\epsilon_{1;p}}(\\boldsymbol\\kappa) = (\\RE\\,N)^{-1}_{p,1}\\widehat{S}^{(1,0)}_{resid;1}(0)+(\\RE\\,N)^{-1}_{p,2}\\widehat{S}^{(1,0)}_{resid;2}(0) + (\\RE\\,N)^{-1}_{p,3}\\widehat{S}^{(1,0)}_{resid;3}(0)\\\\\n",
    "\\end{equation*}\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\large\n",
    "\\begin{align*}\n",
    "\\Rightarrow\\widehat{\\epsilon_{1;p}}(\\boldsymbol\\kappa) &= (\\RE\\,N)^{-1}_{p,1}\\sum_{j=1}^{N_I}\\kappa_j^2\\left(\\widehat{P_j(0)}-\\widehat{P(0)}\\right)\\left.\\frac{\\partial M_j}{\\partial T_1}\\right\\rvert_{\\theta=\\theta_0}M_j(\\theta_0) \\\\ \n",
    "&+(\\RE\\,N)^{-1}_{p,2}\\sum_{j=1}^{N_I}\\kappa_j^2\\left(\\widehat{P_j(0)}-\\widehat{P(0)}\\right)\\left.\\frac{\\partial M_j}{\\partial T_2}\\right\\rvert_{\\theta=\\theta_0}M_j(\\theta_0) \\\\ \n",
    "&+(\\RE\\,N)^{-1}_{p,3}\\sum_{j=1}^{N_I}\\kappa_j^2\\left(\\widehat{P_j(0)}-\\widehat{P(0)}\\right)\\left.\\frac{\\partial M_j}{\\partial \\rho}\\right\\rvert_{\\theta=\\theta_0}M_j(\\theta_0)\n",
    "\\end{align*}\\tag{2}\n",
    "$$\n",
    "\n",
    "\n",
    "### General form of  $\\widehat{\\epsilon_2}(\\zeta)$ terms\n",
    "$$\n",
    "\\widehat{\\epsilon_{2;p}}(\\zeta) = \\sum_{q}\\E_{2}(\\zeta)_{p,q}\\widehat{\\theta_1}(\\zeta)_q \\small\\text{ where, }\\quad\n",
    "\\E_2(\\zeta)_{p,q} = \\sum_r (\\RE\\,N)^{-1}_{p,r}\\widehat{S}^{(1,1)}_{\\text{resid; }r,q}(\\zeta)\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\begin{align*}\n",
    "\\widehat{\\epsilon_{2;p}}(\\zeta) &= \\sum_q \\widehat{\\theta_{1;q}}(\\zeta)\\sum_r (\\RE\\,N)^{-1}_{p,r}\\widehat{S}^{(1,1)}_{\\text{resid; }r,q}(\\zeta)\\\\\n",
    "&= \\sum_q \\widehat{\\theta_{1;q}}(\\zeta)\\left\\{(\\RE\\,N)^{-1}_{p,1}\\widehat{S}^{(1,1)}_{\\text{resid; }1,q}(\\zeta)+(\\RE\\,N)^{-1}_{p,2}\\widehat{S}^{(1,1)}_{\\text{resid; }2,q}(\\zeta)+(\\RE\\,N)^{-1}_{p,3}\\widehat{S}^{(1,1)}_{\\text{resid; }3,q}(\\zeta)\\right\\}\n",
    "\\end{align*}\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\large\n",
    "\\begin{align*}\n",
    "\\Rightarrow\\widehat{\\epsilon_{2;p}}(\\boldsymbol{\\zeta,\\kappa}) &= \\widehat{\\theta_{1;1}}(\\zeta)\\left\\{(\\RE\\,N)^{-1}_{p,1}\\widehat{S}^{(1,1)}_{\\text{resid; }1,1}(\\zeta)+(\\RE\\,N)^{-1}_{p,2}\\widehat{S}^{(1,1)}_{\\text{resid; }2,1}(\\zeta)+(\\RE\\,N)^{-1}_{p,3}\\widehat{S}^{(1,1)}_{\\text{resid; }3,1}(\\zeta) \\right\\}\\\\\n",
    "&+ \\widehat{\\theta_{1;2}}(\\zeta)\\left\\{(\\RE\\,N)^{-1}_{p,1}\\widehat{S}^{(1,1)}_{\\text{resid; }1,2}(\\zeta)+(\\RE\\,N)^{-1}_{p,2}\\widehat{S}^{(1,1)}_{\\text{resid; }2,2}(\\zeta)+(\\RE\\,N)^{-1}_{p,3}\\widehat{S}^{(1,1)}_{\\text{resid; }3,2}(\\zeta) \\right\\}\\\\\n",
    "&+ \\widehat{\\theta_{1;3}}(\\zeta)\\left\\{(\\RE\\,N)^{-1}_{p,1}\\widehat{S}^{(1,1)}_{\\text{resid; }1,3}(\\zeta)+(\\RE\\,N)^{-1}_{p,2}\\widehat{S}^{(1,1)}_{\\text{resid; }2,3}(\\zeta)+(\\RE\\,N)^{-1}_{p,3}\\widehat{S}^{(1,1)}_{\\text{resid; }3,3}(\\zeta) \\right\\}\n",
    "\\end{align*}\\tag{3}\n",
    "$$\n",
    "\n",
    "**Note:** In the above equation, once we plug in the values from the $S^{(1,1)}_{\\text{resid}}(\\zeta)$ matrix, the $\\boldsymbol\\kappa$ dependence is evident. It is omitted for simpler notations. \n",
    "\n",
    "\n",
    "<!-- For a particular $k$-space cordinate $\\zeta$ and $n$ number of parameters the $(r,c)$ element of matrix $\\E_2$ is given as\n",
    "$$\n",
    "\\begin{align*}\\label{eq:E3}\n",
    "\\large\n",
    "\\boxed{\\E_2(\\zeta;\\boldsymbol\\kappa)_{r,c} = (\\RE\\,N)^{-1}_{r,1}\\hat{S}^{(1,1)}_{\\text{resid};1,c}(\\zeta) + (\\RE\\,N)^{-1}_{r,2}\\hat{S}^{(1,1)}_{\\text{resid};2,c}(\\zeta) \\ldots + (\\RE\\,N)^{-1}_{r,n}\\hat{S}^{(1,1)}_{\\text{resid};n,c}(\\zeta)}\n",
    "\\end{align*}\n",
    "$$ -->\n",
    "\n",
    "### Some observations\n",
    "- While $\\widehat{\\epsilon_{2;p}}(\\boldsymbol{\\zeta,\\kappa})$ depends on $\\boldsymbol{\\zeta,\\kappa}$, the $\\widehat{\\epsilon_{1;p}}(\\boldsymbol\\kappa)$ term depends only on $\\boldsymbol\\kappa$.\n",
    "- The terms $(\\RE\\,N)^{-1}_{p,1},(\\RE\\,N)^{-1}_{p,2},(\\RE\\,N)^{-1}_{p,3}$ form the p<sup>th</sup> row of matrix $(\\RE\\,N)^{-1}$. \n",
    "- Similarly, the terms $\\hat{S}^{(1,1)}_{\\text{resid};1,1}(\\zeta),\\hat{S}^{(1,1)}_{\\text{resid};2,1}(\\zeta),\\hat{S}^{(1,1)}_{\\text{resid};3,1}(\\zeta)$ form the 1<sup>st</sup> column of matrix $\\hat{S}^{(1,1)}_{\\text{resid}}(\\zeta)$. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81221728",
   "metadata": {},
   "source": [
    "## Objective functions:\n",
    "\n",
    "Now we minimize the overall error $\\widehat{\\epsilon_1}+\\widehat{\\epsilon_2}$. Let this overall error be  \n",
    "$$\n",
    "\\large\n",
    "\\G(\\boldsymbol\\zeta;\\boldsymbol\\kappa) = \\widehat{\\epsilon_1}+\\widehat{\\epsilon_2} = \n",
    "\\begin{bmatrix}\n",
    "\\G_1\\\\\n",
    "\\G_2\\\\\n",
    "\\G_3\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "Taking the Jacobian of the overall error\n",
    "$$\n",
    "\\large\n",
    "\\begin{align*}\n",
    "\\D \\Gamma =\n",
    "\\begin{bmatrix}\n",
    "\\frac{\\partial\\G_1}{\\partial \\kappa_1} & \\dots & \\frac{\\partial\\G_1}{\\partial \\kappa_{N_I}}\\\\\n",
    "\\frac{\\partial\\G_2}{\\partial \\kappa_1} & \\dots & \\frac{\\partial\\G_2}{\\partial \\kappa_{N_I}}\\\\\n",
    "\\frac{\\partial\\G_3}{\\partial \\kappa_1} & \\dots & \\frac{\\partial\\G_3}{\\partial \\kappa_{N_I}}\n",
    "\\end{bmatrix}\n",
    "\\end{align*}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9950f635",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddcd942f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5ca77e52",
   "metadata": {},
   "source": [
    "## Some drafts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b709bf0d",
   "metadata": {},
   "source": [
    "## Objective functions: \n",
    "\n",
    "1. $$\\min \\underset{k,p,q}{\\max}\\E_2(k)_{p,q}$$ \n",
    "\n",
    "2. <u>*Least square formulation*</u>  \n",
    "Minimization in least square sense is given by\n",
    "$$\n",
    "\\large\n",
    "argmin_\\beta\\sum_{i=1}^m\\left[v_i -f(u_i;\\boldsymbol\\beta) \\right]^2\n",
    "$$\n",
    "\n",
    " In our case the residuals $v_i -f(u_i;\\boldsymbol\\beta)=\\E_2(\\zeta;\\boldsymbol\\kappa)_{r,c}$\n",
    "\n",
    "$$\n",
    "\\large\n",
    "\\therefore\\quad argmin_\\boldsymbol\\kappa\\sum_{r,c}\\left[ \\E_2(\\zeta;\\boldsymbol\\kappa)_{r,c}\\right]^2\n",
    "$$\n",
    "**To-Do:** Include $\\E_1$ terms as well.\n",
    "\n",
    "### Minimization\n",
    "\n",
    "For the above objective function, we construct a vector $E$ with elements as the individual $\\E_2$ terms found from equation $(2)$ and compute its jacobian $\\D E$. For the general case of $n=3$ parameters and a $k-$space grid of size $[m_1\\times m_2]$, $E$ and $\\D E$ are given as:\n",
    "\n",
    "$$\n",
    "\\begin{align*}\\label{eq:resid}\\tag{3}\n",
    "\\large\n",
    "E =\n",
    "\\begin{bmatrix}\n",
    "\\E_2(kx_1,ky_1)_{1,1}\\\\\n",
    "\\vdots\\\\\n",
    "\\E_2(kx_{m_1},ky_{m_2})_{3,1}\\\\\n",
    "\\E_2(kx_1,ky_1)_{1,2}\\\\\n",
    "\\vdots\\\\\n",
    "\\E_2(kx_{m_1},ky_{m_2})_{3,2}\\\\\n",
    "\\E_2(kx_1,ky_1)_{1,3}\\\\\n",
    "\\vdots\\\\\n",
    "\\E_2(kx_{m_1},ky_{m_2})_{3,3}\n",
    "\\end{bmatrix}\n",
    "\\end{align*}\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\large\n",
    "\\begin{align*}\n",
    "\\D E =\n",
    "\\begin{bmatrix}\n",
    "\\frac{\\partial\\E_2(kx_1,ky_1)_{1,1}}{\\partial \\kappa_1} & \\dots & \\frac{\\partial\\E_2(kx_1,ky_1)_{1,1}}{\\partial \\kappa_{N_I}}\\\\\n",
    "\\vdots & \\ddots & \\vdots\\\\\n",
    "\\frac{\\partial\\E_2(kx_{m_1},ky_{m_2})_{3,3}}{\\partial \\kappa_1} & \\dots & \\frac{\\partial\\E_2(kx_{m_1},ky_{m_2})_{3,3}}{\\partial \\kappa_{N_I}}\n",
    "\\end{bmatrix}\n",
    "\\end{align*}\n",
    "$$\n",
    "\n",
    "**Note** that $\\E_2$ has $3\\times3=9$ elements for each $k$-space coordinate. $\\therefore$ the length of vector $E$ is $9m_1m_2$ and the size of jacobian $\\D E$ is $9m_1m_2 \\times N_I$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d04c535",
   "metadata": {},
   "source": [
    "## Guass-Newton algorithm (GNA)\n",
    "Given a set of $m$ empirical observations $(u_i,v_i)$ of independent and dependent variables, the parameter vector $\\boldsymbol\\beta$ of the *model curve* $\\mathbf{f}(\\boldsymbol{u;\\beta})$ is estimated using the iterative algorithm:\n",
    "\n",
    "> ### Algorithm\n",
    ">\n",
    "> 1. Start with an initial guess for $\\boldsymbol{\\beta}$.\n",
    "> 2. Compute the residual vector $\\left[\\mathbf {v} -\\mathbf {f} \\left({\\boldsymbol {u;\\beta}}\\right)\\right]\\quad\\forall(x,y)$\n",
    "> 3. Compute the Jacobian matrix $\\mathbf{J}$ using $\\boldsymbol{\\beta}$ and $x_i$.\n",
    "> 4. Solve for $\\boldsymbol {\\delta }$: $\\mathbf{J}^{\\mathrm {T}}\\mathbf {J} {\\boldsymbol {\\delta }}=\\mathbf {J} ^{\\mathrm {T} }\\left[\\mathbf {v} -\\mathbf {f} \\left({\\boldsymbol {u;\\beta }}\\right)\\right],$ where $\\boldsymbol {\\delta }$ is the parameter correction vector\n",
    "> 5. Update the parameter ${\\boldsymbol {\\beta }} = {\\boldsymbol {\\beta }} + \\boldsymbol {\\delta }$ and iterate till stopping criterion is reached.\n",
    "\n",
    "In our case:\n",
    "- The $\\mathbf{f}$ is ??\n",
    "- The residual vector in step 2 is given by equation $(3)$.\n",
    "- parameter $\\boldsymbol{\\beta}$ is the vector of scaling factors $\\boldsymbol\\kappa=[\\kappa_1,\\kappa_2,\\dots,\\kappa_{N_I}]$ \n",
    "- $u_i$ corresponds to a k-space point $(kx_i, ky_i)$.\n",
    "- what are the $v_i$??"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e65b29be",
   "metadata": {},
   "source": [
    "## Levenberg–Marquardt algorithm (LMA)\n",
    "> Change the equation in step 4 of GNA to ${\\displaystyle \\left[\\mathbf {J} ^{\\mathrm {T} }\\mathbf {J} +\\lambda \\operatorname {diag} \\left(\\mathbf {J} ^{\\mathrm {T} }\\mathbf {J} \\right)\\right]{\\boldsymbol {\\delta }}=\\mathbf {J} ^{\\mathrm {T} }\\left[\\mathbf {y} -\\mathbf {f} \\left({\\boldsymbol {\\beta }}\\right)\\right],}$ where $\\lambda$ is a damping factor."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff19879b",
   "metadata": {},
   "source": [
    "## Julia implementations \n",
    "\n",
    "### LMA\n",
    "The library [LsqFit.jl](https://julianlsolvers.github.io/LsqFit.jl/latest/getting_started/) implements the LMA algorithm using \n",
    "`curve_fit()` function. The call to the function looks like:\n",
    "```julia\n",
    "fit = curve_fit(model, [jacobian], x, y, [w,] p0; kwargs...)\n",
    "``` \n",
    "- `model`: function that takes two arguments (x, params)\n",
    "- `jacobian`: (optional) function that returns the Jacobian matrix of model\n",
    "- `x`: the independent variable\n",
    "- `y`: the dependent variable that constraints model\n",
    "- `w`: (optional) weight applied to the residual; can be a vector (of length(x) size or empty) or matrix (inverse covariance  matrix)\n",
    "- `p0`: initial guess of the model parameters\n",
    "- `kwargs`: tuning parameters for fitting, passed to levenberg_marquardt, such as maxIter, show_trace or lower and upper bounds\n",
    "\n",
    "If a Jacobian is not provided, the central finite difference scheme is used to approximate the Jacobian. It is also possible to use forward mode automatic differentiation as implemented in [ForwardDiff.jl](https://juliadiff.org/ForwardDiff.jl/stable/) by using the `autodiff=:forwarddiff` keyword.\n",
    "\n",
    "### BFGS\n",
    "The library [Optim.jl](https://julianlsolvers.github.io/Optim.jl/stable/#user/minimization/) has the option to use BFGS algorithm.\n",
    "```julia\n",
    "Optim.minimizer(optimize(f, initial_x, BFGS(); autodiff = :forward))\n",
    "``` "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79a6a682",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c49b6399",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff5a3a6a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d20a9f1e",
   "metadata": {},
   "source": [
    "## Cross talk error term $\\mathcal{E}_2$\n",
    "\\begin{align*}\n",
    "\\Large\n",
    "\\mathcal{E}_2(k)_{p,q} = \\sum_r (\\RE\\,N)^{-1}_{p,r}\\hat{S}^{(1,1)}_{\\text{resid; }r,q}(k)\n",
    "\\end{align*}\n",
    "$\\mathcal{E}_2(k)_{p,q}$ is a $N_p\\times N_p$ matrix for each $k$\n",
    "\n",
    "### For $n=3$ parameter case ($T_1, T_2$ and $\\rho$)  \n",
    "\n",
    "\n",
    "So we have $3\\times3=9$ entries for each $k$-space coordinate. For a $k-$space grid of $[m_1\\times m_2]$, we construct the vector $E$ with elements as the elements of the $\\mathcal{E}$ matrix. Note that vector $E$ has a length of $9m_1m_2$.\n",
    "$$\n",
    "\\begin{align*}\n",
    "E =\n",
    "\\begin{bmatrix}\n",
    "\\mathcal{E}_2(kx_1,ky_1)_{1,1}\\\\\n",
    "\\vdots\\\\\n",
    "\\mathcal{E}_2(kx_{m_1},ky_{m_2})_{1,1}\\\\\n",
    "\\mathcal{E}_2(kx_1,ky_1)_{2,1}\\\\\n",
    "\\vdots\\\\\n",
    "\\mathcal{E}_2(kx_{m_1},ky_{m_2})_{2,1}\\\\\n",
    "\\mathcal{E}_2(kx_1,ky_1)_{3,1}\\\\\n",
    "\\vdots\\\\\n",
    "\\mathcal{E}_2(kx_{m_1},ky_{m_2})_{3,1}\\\\\n",
    "\\mathcal{E}_2(kx_1,ky_1)_{1,2}\\\\\n",
    "\\vdots\\\\\n",
    "\\mathcal{E}_2(kx_{m_1},ky_{m_2})_{1,2}\\\\\n",
    "\\mathcal{E}_2(kx_1,ky_1)_{2,2}\\\\\n",
    "\\vdots\\\\\n",
    "\\mathcal{E}_2(kx_{m_1},ky_{m_2})_{2,2}\\\\\n",
    "\\mathcal{E}_2(kx_1,ky_1)_{3,2}\\\\\n",
    "\\vdots\\\\\n",
    "\\mathcal{E}_2(kx_{m_1},ky_{m_2})_{3,2}\\\\\n",
    "\\mathcal{E}_2(kx_1,ky_1)_{1,3}\\\\\n",
    "\\vdots\\\\\n",
    "\\mathcal{E}_2(kx_{m_1},ky_{m_2})_{1,3}\\\\\n",
    "\\mathcal{E}_2(kx_1,ky_1)_{2,3}\\\\\n",
    "\\vdots\\\\\n",
    "\\mathcal{E}_2(kx_{m_1},ky_{m_2})_{2,3}\\\\\n",
    "\\mathcal{E}_2(kx_1,ky_1)_{3,3}\\\\\n",
    "\\vdots\\\\\n",
    "\\mathcal{E}_2(kx_{m_1},ky_{m_2})_{3,3}\n",
    "\\end{bmatrix}\n",
    "\\end{align*}\n",
    "$$\n",
    "*We now try to minimize the $\\left\\lVert E \\right\\rVert^2$, where $\\left\\lVert . \\right\\rVert$ is the $\\ell_2$ norm*"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
